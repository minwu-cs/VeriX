{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1iCy4DONInXgbg5_VNnijgDrRXkYWoadk","authorship_tag":"ABX9TyMjhegCGQA0+6m0MT38nE10"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["##### set up"],"metadata":{"id":"Y9e0tVJl6_dW"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"ghNwKHQkVTYx","executionInfo":{"status":"ok","timestamp":1708981971852,"user_tz":480,"elapsed":162254,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"551f7a2a-b7f2-47d4-c370-6a2fe6eb6228"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.0.1\n","  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.3)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1)\n","  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (67.7.2)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.42.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.27.9)\n","Collecting lit (from triton==2.0.0->torch==2.0.1)\n","  Downloading lit-17.0.6.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=dc7e0cb33a016e0d85cea82c385d6780ad7de91a90c5c04181e38ff454bc7363\n","  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu121\n","    Uninstalling torch-2.1.0+cu121:\n","      Successfully uninstalled torch-2.1.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-17.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n"]}],"source":["!pip install torch==2.0.1"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5s5DjZRcukHX","executionInfo":{"status":"ok","timestamp":1708981974668,"user_tz":480,"elapsed":2834,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.datasets import mnist\n","import keras\n","import torch"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"qJNvyRa5v_o1","executionInfo":{"status":"ok","timestamp":1708981974668,"user_tz":480,"elapsed":6,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["import sys, os\n","sys.path.append(sys.path.append('drive/My Drive/CURIS/VeriX/'))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20474,"status":"ok","timestamp":1708981995137,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":480},"id":"4FjSW9eqwMmD","outputId":"097a6a87-4992-4849-c7e8-6167d1840132"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"IlUDfJ8o53Cj","executionInfo":{"status":"ok","timestamp":1708981995138,"user_tz":480,"elapsed":5,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["saved_data_path = 'drive/MyDrive/CURIS/VeriX/saved_data/'\n","output_path = 'drive/MyDrive/CURIS/VeriX/gtsrb_outputs/'"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"GO7hD5hg2iCf","executionInfo":{"status":"ok","timestamp":1708981995138,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["def softmax(logits):\n","  return np.exp(np.max(logits, axis=1)) / np.sum(np.exp(logits), axis=1)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"UZcB1ZQGt9ij","executionInfo":{"status":"ok","timestamp":1708981995138,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["def plot_ece_bins(logits, labels, n_bins=10):\n","\n","  confidences = softmax(logits)\n","  preds = np.argmax(logits, axis=1)\n","  correct_preds = np.equal(preds, labels)\n","\n","  bin_boundaries = np.linspace(0, 1, n_bins + 1)\n","  bin_accuracies = []\n","  bin_confidences = []\n","  for lower, upper in zip(bin_boundaries[:-1], bin_boundaries[1:]):\n","    elems_acc = correct_preds[(confidences > lower) & (confidences <= upper)]\n","    elems_confidences = confidences[(confidences > lower) & (confidences <= upper)]\n","    num_in_bin = elems_acc.size()[0]\n","    num_correct = torch.sum(elems_acc).item()\n","    accuracy = num_correct / num_in_bin if num_in_bin > 2 else 0\n","    confidence = np.mean(elems_confidences) if num_in_bin > 2 else 0\n","    bin_accuracies.append(accuracy)\n","    bin_confidences.append(confidence)\n","\n","  plt.bar(np.arange(n_bins) / n_bins, bin_accuracies, width=1/n_bins, edgecolor='black', align='edge')\n","  plt.xlim(0, 1)\n","  plt.ylim(0, 1)\n","  plt.gca().set_aspect('equal', adjustable='box')\n","  plt.plot([1, 0], [1, 0], color='red', linestyle='--')"]},{"cell_type":"code","source":["def get_gtsrb_label(index):\n","    get_gtsrb_labels = ['50 mph', '30 mph', 'yield', 'priority road',\n","                        'keep right', 'no passing for large vechicles', '70 mph', '80 mph',\n","                        'road work', 'no passing']\n","    return get_gtsrb_labels[index]"],"metadata":{"id":"R3CHm_031euD","executionInfo":{"status":"ok","timestamp":1708981995138,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["##### load dataset"],"metadata":{"id":"JcV5nKpC1KNg"}},{"cell_type":"code","source":["import pickle\n","\n","gtsrb_path = 'drive/MyDrive/CURIS/VeriX/train_networks/gtsrb.pickle'\n","with open(gtsrb_path, 'rb') as handle:\n","  gtsrb = pickle.load(handle)\n","x_test, y_test = gtsrb['x_test'], gtsrb['y_test']\n","x_test = x_test / 255\n","x_test_tensor = torch.tensor(x_test).to(torch.float32)\n","y_test_tensor = torch.tensor(y_test)"],"metadata":{"id":"CgwVsUPd1LZz","executionInfo":{"status":"ok","timestamp":1708982001246,"user_tz":480,"elapsed":6111,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["load explanation sizes"],"metadata":{"id":"89oztE_d78CN"}},{"cell_type":"code","source":["load_path = output_path + 'gtsrb-10x2-new/'\n","num_to_load = 900\n","# explanation_sizes = np.zeros(num_to_load)\n","# for i in range(num_to_load):\n","#   pth = f'{load_path}index-{i}-gtsrb-10x2-new-300s-heuristic-linf0.005/'\n","#   if os.path.exists(pth):\n","#     files = os.listdir(pth)\n","#     explanation_files = [f for f in files if \"-colour.png\" in f.lower() and 'explanation' in f.lower()]\n","#     if explanation_files:\n","#         explanation_file = explanation_files[0]\n","#         _, explanation_size = explanation_file[:-11].split(\"explanation-\", 1)\n","#         explanation_sizes[i] = int(explanation_size)\n","#     else:\n","#         print(f\"Warning: explanation not found for index {i}\")\n","# pd.to_pickle(explanation_sizes, saved_data_path + 'gtsrb-10x2-new-0.005-sizes')\n","explanation_sizes = pd.read_pickle(saved_data_path + 'gtsrb-10x2-new-0.005-sizes')"],"metadata":{"id":"YGmsmJtg-Tqs","executionInfo":{"status":"ok","timestamp":1708982002435,"user_tz":480,"elapsed":1190,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["explanation_sizes /= 32*32\n","explanation_sizes = torch.tensor(explanation_sizes)"],"metadata":{"id":"fV1iKzADG-PD","executionInfo":{"status":"ok","timestamp":1708982002436,"user_tz":480,"elapsed":2,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["##### load networks"],"metadata":{"id":"9EIuN7Sl0aW1"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"FXQEKraLtt4q","executionInfo":{"status":"ok","timestamp":1708982004948,"user_tz":480,"elapsed":2514,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["keras_model = keras.models.load_model('drive/MyDrive/CURIS/VeriX/networks/gtsrb-10x2-new.h5')\n","weights=keras_model.get_weights()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"unKPhaxWxfun","executionInfo":{"status":"ok","timestamp":1708982005371,"user_tz":480,"elapsed":425,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["from networks.torch_networks import FullyConnectedNetwork\n","torch_model = FullyConnectedNetwork(3072, 10, 10) # torch network with the same architecture"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"pjiEmC1K3s77","executionInfo":{"status":"ok","timestamp":1708982005371,"user_tz":480,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["# copy over weights\n","torch_model.fc1.weight.data=torch.from_numpy(np.transpose(weights[0]))\n","torch_model.fc1.bias.data=torch.from_numpy(weights[1])\n","torch_model.fc2.weight.data=torch.from_numpy(np.transpose(weights[2]))\n","torch_model.fc2.bias.data=torch.from_numpy(weights[3])\n","torch_model.output_layer.weight.data=torch.from_numpy(np.transpose(weights[4]))\n","torch_model.output_layer.bias.data=torch.from_numpy(np.transpose(weights[5]))"]},{"cell_type":"markdown","source":["##### inference"],"metadata":{"id":"a_2yO9k36SRs"}},{"cell_type":"code","source":["logits_gtsrb = torch_model(x_test_tensor.flatten(1)).detach().numpy()\n","softmax_gtsrb = softmax(logits_gtsrb)\n","preds_gtsrb = np.argmax(logits_gtsrb, axis=1)"],"metadata":{"id":"l2BeG8Cl3zDG","executionInfo":{"status":"ok","timestamp":1708982005372,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["sum(((preds_gtsrb - y_test) == 0) / y_test.shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uQ-4TCIf6Jtg","executionInfo":{"status":"ok","timestamp":1708982005372,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"c93eb3d1-2993-4d3d-c1de-55b80867b10c"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8592592592593141"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["##### vanilla temp scaling"],"metadata":{"id":"gqWAM9z26837"}},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader\n","from torch.utils.data.sampler import SubsetRandomSampler\n","\n","test_dataset = TensorDataset(x_test_tensor.flatten(1)[:num_to_load], y_test_tensor[:num_to_load])\n","\n","# Create a DataLoader\n","batch_size = 64  # Set your desired batch size\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, pin_memory=True,\n","                             sampler=SubsetRandomSampler(range(num_to_load)))"],"metadata":{"id":"MqkQC00M7R-8","executionInfo":{"status":"ok","timestamp":1708982005372,"user_tz":480,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from verix_temperature_scaling.temperature_scaling import ModelWithTemperature\n","\n","temp_scaled_model = ModelWithTemperature(torch_model)\n","temp_scaled_model.set_temperature(test_dataloader, 2000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"spJCmKLc79DW","executionInfo":{"status":"error","timestamp":1708982007565,"user_tz":480,"elapsed":2196,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"27c5d5b5-827d-4405-d602-3b85f5464ac0"},"execution_count":20,"outputs":[{"output_type":"error","ename":"DeferredCudaCallError","evalue":"CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\\n    ColabKernelApp.launch_instance()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\\n    app.start()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\\n    self.io_loop.start()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\\n    self._run_once()\\n', '  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\\n    handle._run()\\n', '  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\\n    lambda f: self._run_callback(functools.partial(callback, future))\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\\n    ret = callback()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\\n    self.ctx_run(self.run)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\\n    yielded = self.gen.send(value)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\\n    yield self.process_one()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\\n    runner = Runner(ctx_run, result, future, yielded)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\\n    self.ctx_run(self.run)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\\n    yielded = self.gen.send(value)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\\n    yield gen.maybe_future(dispatch(*args))\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\\n    yielded = ctx_run(next, result)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\\n    yield gen.maybe_future(handler(stream, idents, msg))\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\\n    yielded = ctx_run(next, result)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\\n    self.do_execute(\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\\n    yielded = ctx_run(next, result)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\\n    result = self._run_cell(\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\\n    return runner(coro)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\\n    if (await self.run_code(code, result,  async_=asy)):\\n', '  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"<ipython-input-4-fdf3dcf4fbe5>\", line 9, in <cell line: 9>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0mqueued_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# on ROCm we don't want this check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mCUDA_VERSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getCompiledVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-8caab6887ad0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtemp_scaled_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelWithTemperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtemp_scaled_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_temperature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/content/drive/My Drive/CURIS/VeriX/verix_temperature_scaling/temperature_scaling.py\u001b[0m in \u001b[0;36mset_temperature\u001b[0;34m(self, valid_loader, max_iter)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mvalid_loader\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mset\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \"\"\"\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mnll_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mece_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mECELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    903\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \"\"\"\n\u001b[0;32m--> 905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m                     msg = (f\"CUDA call failed lazily at initialization with error: {str(e)}\\n\\n\"\n\u001b[1;32m    263\u001b[0m                            f\"CUDA call was originally invoked at:\\n\\n{orig_traceback}\")\n\u001b[0;32m--> 264\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mDeferredCudaCallError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_tls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_initializing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\\n    ColabKernelApp.launch_instance()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\\n    app.start()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\\n    self.io_loop.start()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\\n    self._run_once()\\n', '  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\\n    handle._run()\\n', '  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\\n    lambda f: self._run_callback(functools.partial(callback, future))\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\\n    ret = callback()\\n', '  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\\n    self.ctx_run(self.run)\\n', '  File \"..."]}]},{"cell_type":"code","source":["temp_scaled_model = ModelWithTemperature(torch_model)\n","temp_scaled_model.test_const_temperatures(test_dataloader, 0.5, 1.5, 0.01)"],"metadata":{"id":"3pxSlByiRemr","executionInfo":{"status":"aborted","timestamp":1708982007565,"user_tz":480,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["scaling with explanation sizes"],"metadata":{"id":"pH8m4fDyClwA"}},{"cell_type":"code","source":["from verix_temperature_scaling.verix_temperature_scaling import ModelWithVeriXTemperature\n","\n","print('softmax(logits / (T * (1 + explanation_size / 784))')\n","verix_temp_scaled_model = ModelWithVeriXTemperature(torch_model, 'original')\n","verix_temp_scaled_model.set_temperature(test_dataloader, explanation_sizes, 1000)\n","print('\\nsoftmax(logits / (T * (1 + (explanation_size / 784) ** 2))')\n","verix_temp_scaled_model_squared = ModelWithVeriXTemperature(torch_model, 'square')\n","verix_temp_scaled_model_squared.set_temperature(test_dataloader, explanation_sizes, 1000)\n","print('\\nsoftmax(logits / (T * (1 + (explanation_size / 784)) ** 2)')\n","verix_temp_scaled_model_squared2 = ModelWithVeriXTemperature(torch_model, 'square')\n","verix_temp_scaled_model_squared2.set_temperature(test_dataloader, explanation_sizes, 1000)\n"],"metadata":{"id":"fc6I2fVgCpQH","executionInfo":{"status":"aborted","timestamp":1708982007566,"user_tz":480,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":null,"outputs":[]}]}