{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":230449,"status":"ok","timestamp":1691094294381,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"N1rr9uiletu0","outputId":"7eddd9ee-5ef2-4b76-8e81-16a8cc2baf5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow_ranking\n","  Downloading tensorflow_ranking-0.5.2-py2.py3-none-any.whl (150 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.4/150.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.4.0)\n","Collecting numpy==1.23.2 (from tensorflow_ranking)\n","  Downloading numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.16.0)\n","Collecting tensorflow-serving-api<3.0.0,>=2.0.0 (from tensorflow_ranking)\n","  Downloading tensorflow_serving_api-2.13.0-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.56.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.20.3)\n","Collecting tensorflow<3,>=2.13.0 (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.8.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (16.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (23.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (67.7.2)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.0)\n","Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.41.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.13.0->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.2.2)\n","Installing collected packages: typing-extensions, tensorflow-estimator, numpy, keras, tensorboard, tensorflow, tensorflow-serving-api, tensorflow_ranking\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.7.1\n","    Uninstalling typing_extensions-4.7.1:\n","      Successfully uninstalled typing_extensions-4.7.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.22.4\n","    Uninstalling numpy-1.22.4:\n","      Successfully uninstalled numpy-1.22.4\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.3\n","    Uninstalling tensorboard-2.12.3:\n","      Successfully uninstalled tensorboard-2.12.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","Successfully installed keras-2.13.1 numpy-1.23.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-serving-api-2.13.0 tensorflow_ranking-0.5.2 typing-extensions-4.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting adversarial-robustness-toolbox\n","  Downloading adversarial_robustness_toolbox-1.15.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.10.1)\n","Collecting scikit-learn<1.2.0,>=0.22.2 (from adversarial-robustness-toolbox)\n","  Downloading scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.65.0)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed adversarial-robustness-toolbox-1.15.0 scikit-learn-1.1.3\n","Found existing installation: numpy 1.23.2\n","Uninstalling numpy-1.23.2:\n","  Would remove:\n","    /usr/local/bin/f2py\n","    /usr/local/bin/f2py3\n","    /usr/local/bin/f2py3.10\n","    /usr/local/lib/python3.10/dist-packages/numpy-1.23.2.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.10/dist-packages/numpy/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled numpy-1.23.2\n","Collecting numpy==1.23.5\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-ranking 0.5.2 requires numpy==1.23.2, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting keras==2.12\n","  Downloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.13.1\n","    Uninstalling keras-2.13.1:\n","      Successfully uninstalled keras-2.13.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-2.12.0\n","Collecting tensorflow-serving-api==2.12.0\n","  Downloading tensorflow_serving_api-2.12.0-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api==2.12.0) (1.56.2)\n","Collecting protobuf<3.20,>=3.9.2 (from tensorflow-serving-api==2.12.0)\n","  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api==2.12.0) (2.13.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (3.8.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0)\n","  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (16.0.6)\n","Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (23.1)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow<3,>=2.12.0 (from tensorflow-serving-api==2.12.0)\n","  Downloading tensorflow-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (0.4.13)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflow-serving-api==2.12.0) (2.12.0)\n","  Downloading tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.9/585.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Cannot install tensorflow-serving-api, tensorflow-serving-api==2.12.0 and tensorflow==2.13.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n","\u001b[0m\n","The conflict is caused by:\n","    tensorflow-serving-api 2.12.0 depends on protobuf<3.20 and >=3.9.2\n","    tensorflow 2.13.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <5.0.0dev and >=3.20.3\n","    tensorflow-serving-api 2.12.0 depends on protobuf<3.20 and >=3.9.2\n","    tensorflow 2.12.1 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <5.0.0dev and >=3.20.3\n","    tensorflow-serving-api 2.12.0 depends on protobuf<3.20 and >=3.9.2\n","    tensorflow 2.12.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <5.0.0dev and >=3.20.3\n","\n","To fix this you could try to:\n","1. loosen the range of package versions you've specified\n","2. remove package versions to allow pip attempt to solve the dependency conflict\n","\n","\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n","\u001b[0mCollecting tensorflow==2.12\n","  Using cached tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.56.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.13)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (16.0.6)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n","Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n","  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n","  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.41.0)\n","Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.2.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.13.0\n","    Uninstalling tensorflow-estimator-2.13.0:\n","      Successfully uninstalled tensorflow-estimator-2.13.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.13.0\n","    Uninstalling tensorboard-2.13.0:\n","      Successfully uninstalled tensorboard-2.13.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.13.0\n","    Uninstalling tensorflow-2.13.0:\n","      Successfully uninstalled tensorflow-2.13.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-serving-api 2.13.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.12.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0\n"]}],"source":["!pip install tensorflow_ranking\n","!pip install adversarial-robustness-toolbox\n","!pip uninstall numpy\n","!pip install numpy==1.23.5\n","!pip install keras==2.12\n","!pip install tensorflow-serving-api==2.12.0\n","!pip install tensorflow==2.12"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13704,"status":"ok","timestamp":1691094328972,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"5H9Rz649er0f"},"outputs":[],"source":["from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Input, Dense, Reshape, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n","from keras.initializers import GlorotUniform\n","import tensorflow as tf\n","import tensorflow_ranking as tfr\n","from keras.utils.np_utils import to_categorical\n","# import tf2onnx\n","import numpy as np\n","from art.estimators.classification import KerasClassifier\n","from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":25,"status":"ok","timestamp":1691094328973,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"DLBIohSmB0q_"},"outputs":[],"source":["import sys\n","sys.path.append(sys.path.append('/content/drive/My Drive/CURIS/VeriX/train_networks'))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25293,"status":"ok","timestamp":1691094354260,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"NV-yxKvdgV07","outputId":"4ec025cc-572a-4c6d-b483-91d15dc8048a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":308,"status":"ok","timestamp":1691094359458,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"7vdrHaqPmF3d"},"outputs":[],"source":["tf.compat.v1.disable_eager_execution()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1691094360606,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"SBuoH7amV0RX"},"outputs":[],"source":["SEED = 137\n","input_path = 'drive/MyDrive/CURIS/VeriX/train_networks/gtsrb.pickle'\n","output_path = 'drive/MyDrive/CURIS/VeriX/networks/'"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4811,"status":"ok","timestamp":1691094366413,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"X1ZbugoifOQL"},"outputs":[],"source":["# Read and process dataset\n","import pickle\n","with open(input_path, 'rb') as handle:\n","    gtsrb = pickle.load(handle)\n","\n","x_train, y_train, x_valid, y_valid, x_test, y_test = gtsrb.values()\n","x_train = x_train/255\n","x_valid = x_valid/255\n","x_test = x_test/255\n","\n","y_train = to_categorical(y_train)\n","y_valid = to_categorical(y_valid)\n","y_test = to_categorical(y_test)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":338,"status":"ok","timestamp":1691094435554,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"TJij4mzOg34b"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","def plot_figure(image, path=None, cmap=None):\n","    fig = plt.figure()\n","    ax = plt.Axes(fig, [-0.5, -0.5, 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    plt.imshow(image, cmap=cmap)\n","    if path is not None:\n","      plt.savefig(path, bbox_inches='tight')\n","    # plt.close(fig)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1691094436972,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"1xIYjKSw4rC1"},"outputs":[],"source":["def eval_and_save(model):\n","  score = model.evaluate(x_test, y_test, verbose=0)\n","  print(\"Test loss:\", score[0])\n","  print(\"Test accuracy:\", score[1])\n","  model.summary()\n","  model.save(output_path + model.name + '.h5')\n","  # model_proto, _ = tf2onnx.convert.from_keras(model, output_path=output_path + model.name + '.onnx')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691094437490,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"eDilkggLVqLk"},"outputs":[],"source":["def print_weights(model):\n","  for layer in model.layers:\n","    print(layer.get_config())\n","    print(layer.get_weights())"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1691094439005,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"KOOgHT0NXFkU"},"outputs":[],"source":["def train_pgd(model_pgd, num_epochs, alpha):\n","  art_model_pgd = KerasClassifier(model_pgd, clip_values=(0, 1))\n","  art_model_pgd.fit(x_train, y_train,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","  pgd_attack = ProjectedGradientDescent(art_model_pgd, eps=0.015, eps_step=0.001, max_iter=20, verbose=False)\n","\n","  num_samples = len(x_train)\n","  num_adv = int(num_samples * alpha)\n","  num_real = num_samples - num_adv\n","\n","  for i in range(num_epochs - 1):\n","    adv_indices = np.random.choice(x_train.shape[0], size=num_adv, replace=False)\n","    real_indices = np.random.choice(x_train.shape[0], size=num_real, replace=False)\n","    adv_samples = pgd_attack.generate(\n","        x_train[adv_indices],\n","        batch_size=128)\n","    x_real = x_train[real_indices]\n","    y_real = y_train[real_indices]\n","    x_adv = np.concatenate((adv_samples, x_real))\n","    y_adv = np.concatenate((y_train[adv_indices], y_real))\n","    permutation = np.random.permutation(num_samples)\n","    x_adv = x_adv[permutation]\n","    y_adv = y_adv[permutation]\n","    art_model_pgd.fit(x_adv, y_adv,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","    score = model_pgd.evaluate(adv_samples, y_train[adv_indices])\n","    print(f'adv train loss: {score[0]} train acc: {score[1]}')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":504,"status":"ok","timestamp":1691094441049,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"1qWWSKdVxury"},"outputs":[],"source":["def evaluate(model, model_adv):\n","  print('Test loss and accuracy on original test data:')\n","  print('Regular model:')\n","  print(model.evaluate(x_test, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(x_test, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from regular model:')\n","  art_model_regular_pgd = KerasClassifier(model, clip_values=(0, 1))\n","  # pgd_attack_regular = ProjectedGradientDescent(art_model_regular_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_regular.generate(x_test, batch_size=128)\n","  fgm_attack_regular = FastGradientMethod(art_model_regular_pgd)\n","  adv = fgm_attack_regular.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from adv model:')\n","  art_model_adv_pgd = KerasClassifier(model_adv, clip_values=(0, 1))\n","  # pgd_attack_adv = ProjectedGradientDescent(art_model_adv_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_adv.generate(x_test, batch_size=128)\n","  fgm_attack_adv = FastGradientMethod(art_model_adv_pgd, eps=0.015)\n","  adv = fgm_attack_adv.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVzgmf_VZ3a0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"mNzV_fNFZ3zx"},"source":["10x2 fully connected"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1691094442046,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"hpVnc6g7Z3zx"},"outputs":[],"source":["num_epochs = 20\n","alpha = 0.8 # proportion of adv samples"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1499,"status":"ok","timestamp":1691094476577,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"aGV3hmlSZ3zy"},"outputs":[],"source":["# exactly the same initial state of models\n","inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_10x2 = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-10x2-normal')\n","model_10x2_pgd = tf.keras.models.clone_model(model_10x2)\n","model_10x2_pgd.set_weights(model_10x2.get_weights())\n","model_10x2.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model_10x2_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20819,"status":"ok","timestamp":1691094498347,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"orXovehPdB_i","outputId":"f0135605-ec5b-4f45-8ced-c2159f85b1ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","Epoch 1/20\n","17550/17550 [==============================] - 1s 76us/sample - loss: 2.0806 - accuracy: 0.2460 - val_loss: 1.9753 - val_accuracy: 0.2642\n","Epoch 2/20\n","17550/17550 [==============================] - 1s 72us/sample - loss: 1.8193 - accuracy: 0.3488 - val_loss: 1.7415 - val_accuracy: 0.3560\n","Epoch 3/20\n","17550/17550 [==============================] - 1s 63us/sample - loss: 1.6207 - accuracy: 0.4113 - val_loss: 1.6509 - val_accuracy: 0.3665\n","Epoch 4/20\n","17550/17550 [==============================] - 1s 70us/sample - loss: 1.5021 - accuracy: 0.4467 - val_loss: 1.5780 - val_accuracy: 0.4065\n","Epoch 5/20\n","17550/17550 [==============================] - 1s 64us/sample - loss: 1.4006 - accuracy: 0.4874 - val_loss: 1.4828 - val_accuracy: 0.4400\n","Epoch 6/20\n","17550/17550 [==============================] - 1s 68us/sample - loss: 1.3234 - accuracy: 0.5206 - val_loss: 1.4131 - val_accuracy: 0.4688\n","Epoch 7/20\n","17550/17550 [==============================] - 2s 94us/sample - loss: 1.2678 - accuracy: 0.5411 - val_loss: 1.4182 - val_accuracy: 0.4698\n","Epoch 8/20\n","17550/17550 [==============================] - 1s 50us/sample - loss: 1.2270 - accuracy: 0.5487 - val_loss: 1.3403 - val_accuracy: 0.4965\n","Epoch 9/20\n","17550/17550 [==============================] - 1s 46us/sample - loss: 1.1778 - accuracy: 0.5662 - val_loss: 1.3110 - val_accuracy: 0.5071\n","Epoch 10/20\n","17550/17550 [==============================] - 1s 48us/sample - loss: 1.1417 - accuracy: 0.5817 - val_loss: 1.2803 - val_accuracy: 0.5373\n","Epoch 11/20\n","17550/17550 [==============================] - 1s 48us/sample - loss: 1.1097 - accuracy: 0.5962 - val_loss: 1.2462 - val_accuracy: 0.5481\n","Epoch 12/20\n","17550/17550 [==============================] - 1s 53us/sample - loss: 1.0799 - accuracy: 0.6060 - val_loss: 1.2270 - val_accuracy: 0.5690\n","Epoch 13/20\n","17550/17550 [==============================] - 1s 54us/sample - loss: 1.0621 - accuracy: 0.6128 - val_loss: 1.1972 - val_accuracy: 0.5608\n","Epoch 14/20\n","17550/17550 [==============================] - 1s 56us/sample - loss: 1.0364 - accuracy: 0.6239 - val_loss: 1.1874 - val_accuracy: 0.5741\n","Epoch 15/20\n","17550/17550 [==============================] - 1s 56us/sample - loss: 1.0088 - accuracy: 0.6323 - val_loss: 1.2384 - val_accuracy: 0.5784\n","Epoch 16/20\n","17550/17550 [==============================] - 1s 55us/sample - loss: 0.9984 - accuracy: 0.6354 - val_loss: 1.1390 - val_accuracy: 0.5838\n","Epoch 17/20\n","17550/17550 [==============================] - 1s 51us/sample - loss: 0.9659 - accuracy: 0.6522 - val_loss: 1.1374 - val_accuracy: 0.5992\n","Epoch 18/20\n","17550/17550 [==============================] - 1s 39us/sample - loss: 0.9549 - accuracy: 0.6537 - val_loss: 1.1434 - val_accuracy: 0.6034\n","Epoch 19/20\n","17550/17550 [==============================] - 1s 38us/sample - loss: 0.9385 - accuracy: 0.6587 - val_loss: 1.1132 - val_accuracy: 0.6131\n","Epoch 20/20\n","17550/17550 [==============================] - 1s 38us/sample - loss: 0.9213 - accuracy: 0.6623 - val_loss: 1.1142 - val_accuracy: 0.6313\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7b8ab011f6a0>"]},"metadata":{},"execution_count":18}],"source":["# normally train\n","model_10x2.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwAsxafqKb9u","executionInfo":{"status":"ok","timestamp":1691095311356,"user_tz":420,"elapsed":808443,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"4c3f4215-2fbe-4a1c-9065-625058248ea5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 42us/sample - loss: 2.1278 - accuracy: 0.1945 - val_loss: 1.9294 - val_accuracy: 0.2677\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 41us/sample - loss: 1.9419 - accuracy: 0.2514 - val_loss: 1.7440 - val_accuracy: 0.3128\n","adv train loss: 1.8401963530782282 train acc: 0.2909544110298157\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 40us/sample - loss: 1.8050 - accuracy: 0.2934 - val_loss: 1.6379 - val_accuracy: 0.3205\n","adv train loss: 1.742366678490598 train acc: 0.3102564215660095\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 1.7008 - accuracy: 0.3157 - val_loss: 1.5434 - val_accuracy: 0.3435\n","adv train loss: 1.6581616098045284 train acc: 0.3194444477558136\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 1.6082 - accuracy: 0.3831 - val_loss: 1.4560 - val_accuracy: 0.4546\n","adv train loss: 1.5711570544120592 train acc: 0.3957265019416809\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 1.5241 - accuracy: 0.4191 - val_loss: 1.3632 - val_accuracy: 0.5014\n","adv train loss: 1.4659274699681166 train acc: 0.4554843306541443\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 35us/sample - loss: 1.5164 - accuracy: 0.3945 - val_loss: 1.3197 - val_accuracy: 0.5134\n","adv train loss: 1.4438632017526871 train acc: 0.4297720789909363\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 41us/sample - loss: 1.4666 - accuracy: 0.4116 - val_loss: 1.2897 - val_accuracy: 0.5210\n","adv train loss: 1.4282874526461304 train acc: 0.42720797657966614\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 43us/sample - loss: 1.4149 - accuracy: 0.4347 - val_loss: 1.2473 - val_accuracy: 0.5176\n","adv train loss: 1.369981384956599 train acc: 0.4614672362804413\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 42us/sample - loss: 1.3803 - accuracy: 0.4235 - val_loss: 1.2617 - val_accuracy: 0.5231\n","adv train loss: 1.40189935604052 train acc: 0.4227920174598694\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 40us/sample - loss: 1.3563 - accuracy: 0.4626 - val_loss: 1.2297 - val_accuracy: 0.5244\n","adv train loss: 1.341900574651539 train acc: 0.4583333432674408\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 1.3404 - accuracy: 0.4506 - val_loss: 1.2979 - val_accuracy: 0.4627\n","adv train loss: 1.4305806741415605 train acc: 0.4394586980342865\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 29us/sample - loss: 1.2967 - accuracy: 0.4717 - val_loss: 1.1629 - val_accuracy: 0.5568\n","adv train loss: 1.2451994472759063 train acc: 0.49928775429725647\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 0s 28us/sample - loss: 1.3388 - accuracy: 0.4526 - val_loss: 1.1553 - val_accuracy: 0.5498\n","adv train loss: 1.3110572040590465 train acc: 0.4584045708179474\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 29us/sample - loss: 1.3235 - accuracy: 0.4511 - val_loss: 1.1397 - val_accuracy: 0.5485\n","adv train loss: 1.2490984568229089 train acc: 0.49857550859451294\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 1.3333 - accuracy: 0.4444 - val_loss: 1.1262 - val_accuracy: 0.5708\n","adv train loss: 1.2569836028960355 train acc: 0.47678062319755554\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 1.3101 - accuracy: 0.4563 - val_loss: 1.1168 - val_accuracy: 0.5705\n","adv train loss: 1.2458899066658782 train acc: 0.4920940101146698\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 40us/sample - loss: 1.2947 - accuracy: 0.4610 - val_loss: 1.1259 - val_accuracy: 0.5782\n","adv train loss: 1.2380698718236722 train acc: 0.49451565742492676\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 42us/sample - loss: 1.2944 - accuracy: 0.4725 - val_loss: 1.1188 - val_accuracy: 0.5699\n","adv train loss: 1.2261771056047532 train acc: 0.5166666507720947\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 42us/sample - loss: 1.2728 - accuracy: 0.4775 - val_loss: 1.1095 - val_accuracy: 0.5744\n","adv train loss: 1.2218233428110086 train acc: 0.503917396068573\n"]}],"source":["# adversarial training\n","train_pgd(model_10x2_pgd, num_epochs, alpha)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5254,"status":"ok","timestamp":1691095922516,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"bLd8L1TFZ3zy","outputId":"5dc1c1e0-ee20-4d21-bb01-f8b9199681d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[1.114243170067116, 0.63132715]\n","Adv model:\n","[1.1094543839678352, 0.5743827]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[48.42848937423141, 0.07067901]\n","Adv model:\n","[7.0730528101509, 0.11851852]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[1.2830199456509248, 0.5544753]\n","Adv model:\n","[1.3822447211654099, 0.4425926]\n"]}],"source":["evaluate(model_10x2, model_10x2_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1691048571309,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"Sq1aR3WSTgbu","outputId":"85a8d6a9-3c5c-4108-ba7c-a34687ff48bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["gtsrb-100x2.h5\t\t mnist-30x2-normal.h5\n","gtsrb-100x2.onnx\t mnist-30x2-normal.onnx\n","gtsrb-10x2.h5\t\t mnist-30x2.onnx\n","gtsrb-10x2.onnx\t\t mnist-30x2-pgd.h5\n","gtsrb-30x2.h5\t\t mnist-30x2-pgd.onnx\n","gtsrb-30x2.onnx\t\t mnist-bigger-cnn.h5\n","gtsrb-cnn-3x3.h5\t mnist-bigger-cnn.onnx\n","gtsrb-cnn-3x3.onnx\t mnist-bigger-cnn-pooling.h5\n","gtsrb-sota.h5\t\t mnist-bigger-cnn-pooling.onnx\n","gtsrb-sota.onnx\t\t mnist-cnn-3x3.h5\n","mnist-100x2.h5\t\t mnist-cnn-3x3.onnx\n","mnist-100x2-normal.h5\t mnist-cnn-pooling.h5\n","mnist-100x2-normal.onnx  mnist-cnn-pooling.onnx\n","mnist-100x2.onnx\t mnist-simple-cnn.h5\n","mnist-100x2-pgd.h5\t mnist-simple-cnn-normal.h5\n","mnist-100x2-pgd.onnx\t mnist-simple-cnn-normal.onnx\n","mnist-10x2.h5\t\t mnist-simple-cnn.onnx\n","mnist-10x2-normal.h5\t mnist-simple-cnn-pgd.h5\n","mnist-10x2-normal.onnx\t mnist-simple-cnn-pgd.onnx\n","mnist-10x2.onnx\t\t mnist-sota.h5\n","mnist-10x2-pgd.h5\t mnist-sota-normal.h5\n","mnist-10x2-pgd.onnx\t mnist-sota.onnx\n","mnist-30x2.h5\t\t mnist-sota-pgd.h5\n"]}],"source":["!ls drive/MyDrive/CURIS/VeriX/networks/"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15806,"status":"ok","timestamp":1691095952768,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"jnYz08fiWe4p","outputId":"bf64d03a-35d8-4da5-a9db-32998aec8f60"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","Epoch 1/20\n","17550/17550 [==============================] - 1s 56us/sample - loss: 1.8958 - accuracy: 0.3925 - val_loss: 1.4788 - val_accuracy: 0.5802\n","Epoch 2/20\n","17550/17550 [==============================] - 1s 44us/sample - loss: 1.1946 - accuracy: 0.6839 - val_loss: 1.0486 - val_accuracy: 0.6932\n","Epoch 3/20\n","17550/17550 [==============================] - 1s 45us/sample - loss: 0.8496 - accuracy: 0.7834 - val_loss: 0.8576 - val_accuracy: 0.7591\n","Epoch 4/20\n","17550/17550 [==============================] - 1s 45us/sample - loss: 0.6601 - accuracy: 0.8295 - val_loss: 0.7204 - val_accuracy: 0.7852\n","Epoch 5/20\n","17550/17550 [==============================] - 1s 46us/sample - loss: 0.5499 - accuracy: 0.8545 - val_loss: 0.6290 - val_accuracy: 0.8037\n","Epoch 6/20\n","17550/17550 [==============================] - 1s 46us/sample - loss: 0.4767 - accuracy: 0.8744 - val_loss: 0.6255 - val_accuracy: 0.7890\n","Epoch 7/20\n","17550/17550 [==============================] - 1s 46us/sample - loss: 0.4149 - accuracy: 0.8926 - val_loss: 0.5635 - val_accuracy: 0.8131\n","Epoch 8/20\n","17550/17550 [==============================] - 1s 43us/sample - loss: 0.3831 - accuracy: 0.8988 - val_loss: 0.5364 - val_accuracy: 0.8270\n","Epoch 9/20\n","17550/17550 [==============================] - 1s 47us/sample - loss: 0.3359 - accuracy: 0.9157 - val_loss: 0.5330 - val_accuracy: 0.8267\n","Epoch 10/20\n","17550/17550 [==============================] - 1s 46us/sample - loss: 0.3088 - accuracy: 0.9232 - val_loss: 0.4833 - val_accuracy: 0.8461\n","Epoch 11/20\n","17550/17550 [==============================] - 1s 42us/sample - loss: 0.2914 - accuracy: 0.9247 - val_loss: 0.5234 - val_accuracy: 0.8375\n","Epoch 12/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.2815 - accuracy: 0.9258 - val_loss: 0.4381 - val_accuracy: 0.8627\n","Epoch 13/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.2509 - accuracy: 0.9383 - val_loss: 0.4528 - val_accuracy: 0.8625\n","Epoch 14/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.2431 - accuracy: 0.9362 - val_loss: 0.4453 - val_accuracy: 0.8708\n","Epoch 15/20\n","17550/17550 [==============================] - 1s 33us/sample - loss: 0.2251 - accuracy: 0.9402 - val_loss: 0.5085 - val_accuracy: 0.8449\n","Epoch 16/20\n","17550/17550 [==============================] - 1s 32us/sample - loss: 0.2265 - accuracy: 0.9413 - val_loss: 0.4272 - val_accuracy: 0.8776\n","Epoch 17/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.2124 - accuracy: 0.9430 - val_loss: 0.4577 - val_accuracy: 0.8701\n","Epoch 18/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.2041 - accuracy: 0.9454 - val_loss: 0.4065 - val_accuracy: 0.8829\n","Epoch 19/20\n","17550/17550 [==============================] - 1s 33us/sample - loss: 0.1922 - accuracy: 0.9501 - val_loss: 0.4048 - val_accuracy: 0.8906\n","Epoch 20/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.1908 - accuracy: 0.9508 - val_loss: 0.4417 - val_accuracy: 0.8772\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7b8a97fca200>"]},"metadata":{},"execution_count":21}],"source":["inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_30x2 = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-30x2-normal')\n","model_30x2.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model_30x2.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1691095953116,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"a5PYYVbBTbmy"},"outputs":[],"source":["art_model = KerasClassifier(model_30x2, clip_values=(0, 1))\n","fgm_attack = FastGradientMethod(art_model, eps=0.015)\n","adv = fgm_attack.generate(x_test, batch_size=128)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":337,"status":"ok","timestamp":1691095953450,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"VYllgGnRWu6H","outputId":"aa10f1b3-3efb-4cab-d293-1d1f4f5250ae"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.4910753779941135, 0.5089506]"]},"metadata":{},"execution_count":23}],"source":["model_10x2.evaluate(adv, y_test)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1364,"status":"ok","timestamp":1691095954812,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"Civ5bEGiWv1N","outputId":"178a09da-03f7-44b9-9f44-9d381861e54f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.2779113392771027, 0.5197531]"]},"metadata":{},"execution_count":24}],"source":["model_10x2_pgd.evaluate(adv, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":561,"status":"ok","timestamp":1691048649568,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"OF32innbINJ5","outputId":"3ecfd470-da3d-4649-8096-f812e3cea019"},"outputs":[{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["index = 0\n","plot_figure(x_test[index])\n","plot_figure(adv[index])"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2196,"status":"ok","timestamp":1691096990909,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"3YZbUPNsaDfa","outputId":"60c14039-3fca-4667-e896-8532f9276aae"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 1.114243170067116\n","Test accuracy: 0.63132715\n","Model: \"gtsrb-10x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," flatten_1 (Flatten)         (None, 3072)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                30730     \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                110       \n","                                                                 \n"," logit (Dense)               (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 30,950\n","Trainable params: 30,950\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["eval_and_save(model_10x2)\n","# eval_and_save(model_pgd)"]},{"cell_type":"markdown","metadata":{"id":"naNeO7cyZ41Q"},"source":["30x2 fully connected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AuLtM1saZ41Q"},"outputs":[],"source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16045,"status":"ok","timestamp":1691096838409,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"P63H5JuUZ41Q","outputId":"ed45af24-bb8b-492c-da3e-478c43d9bc46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","Epoch 1/20\n","17550/17550 [==============================] - 1s 65us/sample - loss: 1.7168 - accuracy: 0.4768 - val_loss: 1.3442 - val_accuracy: 0.5713\n","Epoch 2/20\n","17550/17550 [==============================] - 1s 48us/sample - loss: 1.0028 - accuracy: 0.7272 - val_loss: 0.9692 - val_accuracy: 0.6731\n","Epoch 3/20\n","17550/17550 [==============================] - 1s 49us/sample - loss: 0.7178 - accuracy: 0.8097 - val_loss: 0.8184 - val_accuracy: 0.7352\n","Epoch 4/20\n","17550/17550 [==============================] - 1s 50us/sample - loss: 0.5680 - accuracy: 0.8557 - val_loss: 0.6792 - val_accuracy: 0.7860\n","Epoch 5/20\n","17550/17550 [==============================] - 1s 48us/sample - loss: 0.4562 - accuracy: 0.8921 - val_loss: 0.6560 - val_accuracy: 0.7900\n","Epoch 6/20\n","17550/17550 [==============================] - 1s 48us/sample - loss: 0.4073 - accuracy: 0.8995 - val_loss: 0.5733 - val_accuracy: 0.8235\n","Epoch 7/20\n","17550/17550 [==============================] - 1s 52us/sample - loss: 0.3431 - accuracy: 0.9190 - val_loss: 0.5031 - val_accuracy: 0.8556\n","Epoch 8/20\n","17550/17550 [==============================] - 1s 52us/sample - loss: 0.3345 - accuracy: 0.9162 - val_loss: 0.4335 - val_accuracy: 0.8852\n","Epoch 9/20\n","17550/17550 [==============================] - 1s 50us/sample - loss: 0.2814 - accuracy: 0.9337 - val_loss: 0.4419 - val_accuracy: 0.8765\n","Epoch 10/20\n","17550/17550 [==============================] - 1s 38us/sample - loss: 0.2555 - accuracy: 0.9393 - val_loss: 0.4149 - val_accuracy: 0.8833\n","Epoch 11/20\n","17550/17550 [==============================] - 1s 37us/sample - loss: 0.2369 - accuracy: 0.9450 - val_loss: 0.4396 - val_accuracy: 0.8789\n","Epoch 12/20\n","17550/17550 [==============================] - 1s 36us/sample - loss: 0.2188 - accuracy: 0.9468 - val_loss: 0.4410 - val_accuracy: 0.8688\n","Epoch 13/20\n","17550/17550 [==============================] - 1s 35us/sample - loss: 0.2422 - accuracy: 0.9362 - val_loss: 0.3657 - val_accuracy: 0.9006\n","Epoch 14/20\n","17550/17550 [==============================] - 1s 35us/sample - loss: 0.2212 - accuracy: 0.9441 - val_loss: 0.4326 - val_accuracy: 0.8866\n","Epoch 15/20\n","17550/17550 [==============================] - 1s 37us/sample - loss: 0.1929 - accuracy: 0.9510 - val_loss: 0.3681 - val_accuracy: 0.9051\n","Epoch 16/20\n","17550/17550 [==============================] - 1s 36us/sample - loss: 0.1873 - accuracy: 0.9534 - val_loss: 0.3592 - val_accuracy: 0.9069\n","Epoch 17/20\n","17550/17550 [==============================] - 1s 35us/sample - loss: 0.1712 - accuracy: 0.9585 - val_loss: 0.4369 - val_accuracy: 0.8776\n","Epoch 18/20\n","17550/17550 [==============================] - 1s 34us/sample - loss: 0.1655 - accuracy: 0.9583 - val_loss: 0.3384 - val_accuracy: 0.9140\n","Epoch 19/20\n","17550/17550 [==============================] - 1s 36us/sample - loss: 0.1718 - accuracy: 0.9551 - val_loss: 0.3573 - val_accuracy: 0.9046\n","Epoch 20/20\n","17550/17550 [==============================] - 1s 35us/sample - loss: 0.1601 - accuracy: 0.9584 - val_loss: 0.3272 - val_accuracy: 0.9176\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7b8a97faee90>"]},"metadata":{},"execution_count":28}],"source":["# normally trained model for compariaon\n","inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-30x2-normal')\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"z4K-thMiZ41R","executionInfo":{"status":"ok","timestamp":1691095975923,"user_tz":420,"elapsed":2,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["# model for adversarial training with pgd\n","inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-30x2-pgd')\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":832084,"status":"ok","timestamp":1691096809346,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"R0E4X0oyZ41R","outputId":"bee2e7cf-4f4d-469e-85d0-14c092f3a53c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 36us/sample - loss: 1.7144 - accuracy: 0.4754 - val_loss: 1.2574 - val_accuracy: 0.6259\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 1.1883 - accuracy: 0.6104 - val_loss: 0.8654 - val_accuracy: 0.7094\n","adv train loss: 1.0077777057971031 train acc: 0.6891738176345825\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 42us/sample - loss: 0.9840 - accuracy: 0.6588 - val_loss: 0.7382 - val_accuracy: 0.7546\n","adv train loss: 0.908269903123209 train acc: 0.6918091177940369\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 46us/sample - loss: 0.8782 - accuracy: 0.6901 - val_loss: 0.6581 - val_accuracy: 0.7870\n","adv train loss: 0.8306793617047475 train acc: 0.7107549905776978\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 0.7783 - accuracy: 0.7295 - val_loss: 0.6007 - val_accuracy: 0.8071\n","adv train loss: 0.7908898593693378 train acc: 0.7215099930763245\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 0.7203 - accuracy: 0.7476 - val_loss: 0.5743 - val_accuracy: 0.8215\n","adv train loss: 0.7301450052152672 train acc: 0.7424501180648804\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 0.6776 - accuracy: 0.7660 - val_loss: 0.5116 - val_accuracy: 0.8441\n","adv train loss: 0.6619886071254045 train acc: 0.7688034176826477\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 43us/sample - loss: 0.6525 - accuracy: 0.7687 - val_loss: 0.4773 - val_accuracy: 0.8543\n","adv train loss: 0.6462730573453115 train acc: 0.7733618021011353\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 44us/sample - loss: 0.6494 - accuracy: 0.7626 - val_loss: 0.5059 - val_accuracy: 0.8460\n","adv train loss: 0.6452499467083531 train acc: 0.7636752128601074\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 0.6165 - accuracy: 0.7821 - val_loss: 0.5138 - val_accuracy: 0.8494\n","adv train loss: 0.6395709677978798 train acc: 0.7644587159156799\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 0.5989 - accuracy: 0.7920 - val_loss: 0.4719 - val_accuracy: 0.8560\n","adv train loss: 0.6335497793648658 train acc: 0.7745726704597473\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 0.5814 - accuracy: 0.7891 - val_loss: 0.4297 - val_accuracy: 0.8736\n","adv train loss: 0.5888690417988008 train acc: 0.7879629731178284\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 31us/sample - loss: 0.5734 - accuracy: 0.7923 - val_loss: 0.4300 - val_accuracy: 0.8724\n","adv train loss: 0.5897914631244464 train acc: 0.7835469841957092\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 43us/sample - loss: 0.5527 - accuracy: 0.8002 - val_loss: 0.4517 - val_accuracy: 0.8590\n","adv train loss: 0.5831509666055695 train acc: 0.7789173722267151\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 47us/sample - loss: 0.5430 - accuracy: 0.8040 - val_loss: 0.4424 - val_accuracy: 0.8759\n","adv train loss: 0.5428881032174808 train acc: 0.7985755205154419\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 33us/sample - loss: 0.5551 - accuracy: 0.7945 - val_loss: 0.4366 - val_accuracy: 0.8667\n","adv train loss: 0.5921619717212144 train acc: 0.7766381502151489\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 30us/sample - loss: 0.5213 - accuracy: 0.8134 - val_loss: 0.3951 - val_accuracy: 0.8944\n","adv train loss: 0.5249965711876198 train acc: 0.816096842288971\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 32us/sample - loss: 0.5615 - accuracy: 0.7903 - val_loss: 0.4217 - val_accuracy: 0.8735\n","adv train loss: 0.5691794387295714 train acc: 0.7905982732772827\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 32us/sample - loss: 0.5331 - accuracy: 0.8085 - val_loss: 0.4311 - val_accuracy: 0.8785\n","adv train loss: 0.5651157609757534 train acc: 0.7922364473342896\n","Train on 17550 samples, validate on 6480 samples\n","17550/17550 [==============================] - 1s 38us/sample - loss: 0.5408 - accuracy: 0.8073 - val_loss: 0.4159 - val_accuracy: 0.8799\n","adv train loss: 0.5267010329285918 train acc: 0.8215099573135376\n"]}],"source":["train_pgd(model_pgd, num_epochs, alpha)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6639,"status":"ok","timestamp":1691096848544,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"n6YOrGfFZ41R","outputId":"2df1524c-3d40-4e2f-c904-3d613ba6524d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.32724312243086323, 0.9175926]\n","Adv model:\n","[0.41593411196897057, 0.87993824]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[54.032532265745566, 0.02962963]\n","Adv model:\n","[20.60650613101912, 0.047376543]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[0.9934929431220632, 0.6845679]\n","Adv model:\n","[0.774662317905897, 0.70092595]\n"]}],"source":["evaluate(model, model_pgd)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":2843,"status":"ok","timestamp":1691096887663,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"0pDytagGOos6"},"outputs":[],"source":["art_model = KerasClassifier(model_10x2, clip_values=(0, 1))\n","fgm_attack = FastGradientMethod(art_model, eps=0.015)\n","adv = fgm_attack.generate(x_test, batch_size=128)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":575,"status":"ok","timestamp":1691096889310,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"outputId":"8c149abd-4b8b-4e77-e842-497d1a3b3f59","id":"LcGV2sOdOos8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[3.3769863764444987, 0.23719136]"]},"metadata":{},"execution_count":31}],"source":["model_10x2.evaluate(adv, y_test)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1691096890647,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"outputId":"8ddb63fd-ae6e-46bc-edd8-b15517f054b6","id":"yVLNiRK1Oos8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.167645913730433, 0.525463]"]},"metadata":{},"execution_count":32}],"source":["model_10x2_pgd.evaluate(adv, y_test)"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1782,"status":"ok","timestamp":1691096913709,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"uj7eSMGRa-K9","outputId":"3238583f-d4e9-4a00-d1ee-2ae96a7a79d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.32724312243086323\n","Test accuracy: 0.9175926\n","Model: \"gtsrb-30x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 3072)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                92190     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 93,430\n","Trainable params: 93,430\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.41593411196897057\n","Test accuracy: 0.87993824\n","Model: \"gtsrb-30x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 3072)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                92190     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 93,430\n","Trainable params: 93,430\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["eval_and_save(model)\n","eval_and_save(model_pgd)"]},{"cell_type":"markdown","metadata":{"id":"6VVT-pBU6xbD"},"source":["100x2 fully connected"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EX0g9sERb6uD"},"outputs":[],"source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34088,"status":"ok","timestamp":1689897000768,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"oURqqMajArni","outputId":"7c93a154-9862-40e4-a724-e78a093e3975"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.3409 - accuracy: 0.9020 - val_loss: 0.1795 - val_accuracy: 0.9455\n","Epoch 2/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1399 - accuracy: 0.9587 - val_loss: 0.1216 - val_accuracy: 0.9630\n","Epoch 3/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0978 - accuracy: 0.9704 - val_loss: 0.1003 - val_accuracy: 0.9675\n","Epoch 4/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0749 - accuracy: 0.9771 - val_loss: 0.0893 - val_accuracy: 0.9709\n","Epoch 5/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.0879 - val_accuracy: 0.9726\n","Epoch 6/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0482 - accuracy: 0.9843 - val_loss: 0.0891 - val_accuracy: 0.9731\n","Epoch 7/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0829 - val_accuracy: 0.9746\n","Epoch 8/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0878 - val_accuracy: 0.9727\n","Epoch 9/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0824 - val_accuracy: 0.9761\n","Epoch 10/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0870 - val_accuracy: 0.9764\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1020 - val_accuracy: 0.9728\n","Epoch 12/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0956 - val_accuracy: 0.9734\n","Epoch 13/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0886 - val_accuracy: 0.9775\n","Epoch 14/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0922 - val_accuracy: 0.9768\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0949 - val_accuracy: 0.9766\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.1032 - val_accuracy: 0.9755\n","Epoch 17/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1317 - val_accuracy: 0.9709\n","Epoch 18/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1117 - val_accuracy: 0.9754\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1143 - val_accuracy: 0.9761\n","Epoch 20/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1072 - val_accuracy: 0.9769\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fc7705c2f50>"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["# normally trained model for compariaon\n","inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-100x2-normal')\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CaPQ3vFIfSZQ"},"outputs":[],"source":["# model for adversarial training with pgd\n","inputs = Input(shape=(32, 32, 3))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-100x2-pgd')\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597711,"status":"ok","timestamp":1689897598465,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"wTxLq2rZX086","outputId":"33a8a113-fc4e-4dc2-ae0f-5ecdc6bf993b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 38us/sample - loss: 0.3485 - accuracy: 0.8993 - val_loss: 0.1720 - val_accuracy: 0.9490\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2155 - accuracy: 0.9358 - val_loss: 0.1238 - val_accuracy: 0.9623\n","adv train loss: 0.11473088092257579 train acc: 0.9653000235557556\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.2434 - accuracy: 0.9307 - val_loss: 0.1162 - val_accuracy: 0.9643\n","adv train loss: 0.10867337775677442 train acc: 0.9684000015258789\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1843 - accuracy: 0.9484 - val_loss: 0.0990 - val_accuracy: 0.9704\n","adv train loss: 0.09152162838528553 train acc: 0.972599983215332\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1614 - accuracy: 0.9539 - val_loss: 0.0952 - val_accuracy: 0.9706\n","adv train loss: 0.08296541338587801 train acc: 0.9761999845504761\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1579 - accuracy: 0.9548 - val_loss: 0.0928 - val_accuracy: 0.9699\n","adv train loss: 0.07537264022231102 train acc: 0.9778000116348267\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1444 - accuracy: 0.9592 - val_loss: 0.0841 - val_accuracy: 0.9738\n","adv train loss: 0.06622250464372337 train acc: 0.9799000024795532\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1376 - accuracy: 0.9608 - val_loss: 0.0896 - val_accuracy: 0.9716\n","adv train loss: 0.06873930878937244 train acc: 0.9797000288963318\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1316 - accuracy: 0.9633 - val_loss: 0.0804 - val_accuracy: 0.9755\n","adv train loss: 0.06325296099297702 train acc: 0.9822333455085754\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.1302 - accuracy: 0.9633 - val_loss: 0.0832 - val_accuracy: 0.9737\n","adv train loss: 0.0614114660859108 train acc: 0.9817666411399841\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1268 - accuracy: 0.9642 - val_loss: 0.0768 - val_accuracy: 0.9766\n","adv train loss: 0.059161939499403036 train acc: 0.9833333492279053\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.1217 - accuracy: 0.9655 - val_loss: 0.0767 - val_accuracy: 0.9754\n","adv train loss: 0.05450291076426705 train acc: 0.984333336353302\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1221 - accuracy: 0.9649 - val_loss: 0.0704 - val_accuracy: 0.9779\n","adv train loss: 0.04780977053120732 train acc: 0.9866666793823242\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.1226 - accuracy: 0.9649 - val_loss: 0.0775 - val_accuracy: 0.9761\n","adv train loss: 0.05007306928460797 train acc: 0.9857000112533569\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.1263 - accuracy: 0.9654 - val_loss: 0.0749 - val_accuracy: 0.9767\n","adv train loss: 0.05070892217954 train acc: 0.9855666756629944\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1179 - accuracy: 0.9656 - val_loss: 0.0699 - val_accuracy: 0.9787\n","adv train loss: 0.04988621731524666 train acc: 0.9851333498954773\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.1159 - accuracy: 0.9671 - val_loss: 0.0671 - val_accuracy: 0.9790\n","adv train loss: 0.04297111075272163 train acc: 0.9879000186920166\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1146 - accuracy: 0.9673 - val_loss: 0.0667 - val_accuracy: 0.9776\n","adv train loss: 0.042188754510506986 train acc: 0.9880333542823792\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1125 - accuracy: 0.9687 - val_loss: 0.0673 - val_accuracy: 0.9792\n","adv train loss: 0.039338898815711336 train acc: 0.9893666505813599\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1170 - accuracy: 0.9677 - val_loss: 0.0680 - val_accuracy: 0.9778\n","adv train loss: 0.040279233229036135 train acc: 0.987933337688446\n"]}],"source":["train_pgd(model_pgd, num_epochs, alpha)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6926,"status":"ok","timestamp":1689897605372,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"4IpKJN3xrYJ2","outputId":"51cc2f04-dbb8-4ed9-dc75-e5c99383547b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.10720364366221183, 0.9769]\n","Adv model:\n","[0.0680444527752581, 0.9778]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[35.847421008300785, 0.0311]\n","Adv model:\n","[1.3557057939052581, 0.599]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[9.888806645202637, 0.1419]\n","Adv model:\n","[17.42983818359375, 0.0171]\n"]}],"source":["evaluate(model, model_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5808,"status":"ok","timestamp":1689897611163,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"qtJuakrFpRT-","outputId":"98eadfd0-696a-475b-b688-8886a8be34f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.10720364366221183\n","Test accuracy: 0.9769\n","Model: \"mnist-100x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.0680444527752581\n","Test accuracy: 0.9778\n","Model: \"mnist-100x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["eval_and_save(model)\n","eval_and_save(model_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"crnHiwZWri6s"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"K1HqrwdNbHAD"},"source":["cnn-simple"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40609,"status":"ok","timestamp":1689897651753,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"lUa502OLbIfq","outputId":"6a7e1b36-afa9-4c5d-f76d-2b1d4e29d829"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.5132 - accuracy: 0.8463 - val_loss: 0.2605 - val_accuracy: 0.9250\n","Epoch 2/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2464 - accuracy: 0.9289 - val_loss: 0.2229 - val_accuracy: 0.9357\n","Epoch 3/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2163 - accuracy: 0.9367 - val_loss: 0.1968 - val_accuracy: 0.9431\n","Epoch 4/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1961 - accuracy: 0.9431 - val_loss: 0.1827 - val_accuracy: 0.9500\n","Epoch 5/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1795 - accuracy: 0.9478 - val_loss: 0.1795 - val_accuracy: 0.9478\n","Epoch 6/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1670 - accuracy: 0.9515 - val_loss: 0.1721 - val_accuracy: 0.9490\n","Epoch 7/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1561 - accuracy: 0.9540 - val_loss: 0.1630 - val_accuracy: 0.9525\n","Epoch 8/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.1471 - accuracy: 0.9562 - val_loss: 0.1538 - val_accuracy: 0.9554\n","Epoch 9/20\n","60000/60000 [==============================] - 2s 35us/sample - loss: 0.1409 - accuracy: 0.9584 - val_loss: 0.1536 - val_accuracy: 0.9557\n","Epoch 10/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.1337 - accuracy: 0.9601 - val_loss: 0.1473 - val_accuracy: 0.9590\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.1288 - accuracy: 0.9612 - val_loss: 0.1525 - val_accuracy: 0.9568\n","Epoch 12/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.1223 - accuracy: 0.9639 - val_loss: 0.1439 - val_accuracy: 0.9592\n","Epoch 13/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1177 - accuracy: 0.9649 - val_loss: 0.1448 - val_accuracy: 0.9595\n","Epoch 14/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1153 - accuracy: 0.9657 - val_loss: 0.1460 - val_accuracy: 0.9574\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1114 - accuracy: 0.9662 - val_loss: 0.1365 - val_accuracy: 0.9619\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1086 - accuracy: 0.9670 - val_loss: 0.1422 - val_accuracy: 0.9609\n","Epoch 17/20\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.1051 - accuracy: 0.9682 - val_loss: 0.1418 - val_accuracy: 0.9596\n","Epoch 18/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1023 - accuracy: 0.9688 - val_loss: 0.1346 - val_accuracy: 0.9624\n","Epoch 19/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.0998 - accuracy: 0.9691 - val_loss: 0.1391 - val_accuracy: 0.9630\n","Epoch 20/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.0978 - accuracy: 0.9706 - val_loss: 0.1403 - val_accuracy: 0.9617\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7fc770397430>"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(32, 32, 3), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=x, name='gtsrb-simple-cnn-normal')\n","\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5eUrlP7UfFp"},"outputs":[],"source":["inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(32, 32, 3), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=x, name='gtsrb-simple-cnn-pgd')\n","\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":655379,"status":"ok","timestamp":1689898308405,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"bWpstsChbnGI","outputId":"e70411e5-ada4-480d-fbd1-266747351bf9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 43us/sample - loss: 0.5137 - accuracy: 0.8450 - val_loss: 0.2625 - val_accuracy: 0.9267\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.4068 - accuracy: 0.8761 - val_loss: 0.2608 - val_accuracy: 0.9228\n","adv train loss: 0.2736689247151216 train acc: 0.9194333553314209\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.4150 - accuracy: 0.8756 - val_loss: 0.2112 - val_accuracy: 0.9388\n","adv train loss: 0.23954009110331537 train acc: 0.9315333366394043\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.4006 - accuracy: 0.8777 - val_loss: 0.2047 - val_accuracy: 0.9413\n","adv train loss: 0.2569413528243701 train acc: 0.9260333180427551\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.3544 - accuracy: 0.8907 - val_loss: 0.1912 - val_accuracy: 0.9460\n","adv train loss: 0.21969784870147704 train acc: 0.9362000226974487\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.3523 - accuracy: 0.8922 - val_loss: 0.1761 - val_accuracy: 0.9487\n","adv train loss: 0.21780159526268641 train acc: 0.9365000128746033\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.3237 - accuracy: 0.9017 - val_loss: 0.1751 - val_accuracy: 0.9482\n","adv train loss: 0.1967509552915891 train acc: 0.9445666670799255\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.3195 - accuracy: 0.9014 - val_loss: 0.1652 - val_accuracy: 0.9506\n","adv train loss: 0.19340279205640157 train acc: 0.9437333345413208\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.3094 - accuracy: 0.9073 - val_loss: 0.1629 - val_accuracy: 0.9524\n","adv train loss: 0.18611354259053867 train acc: 0.9448666572570801\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.3096 - accuracy: 0.9042 - val_loss: 0.1522 - val_accuracy: 0.9547\n","adv train loss: 0.17658340806365014 train acc: 0.947700023651123\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2929 - accuracy: 0.9101 - val_loss: 0.1544 - val_accuracy: 0.9556\n","adv train loss: 0.16760945475498834 train acc: 0.9521333575248718\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2896 - accuracy: 0.9114 - val_loss: 0.1431 - val_accuracy: 0.9560\n","adv train loss: 0.1642782387495041 train acc: 0.9513999819755554\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.2746 - accuracy: 0.9161 - val_loss: 0.1449 - val_accuracy: 0.9558\n","adv train loss: 0.15851731547315914 train acc: 0.9540333151817322\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.2803 - accuracy: 0.9151 - val_loss: 0.1339 - val_accuracy: 0.9595\n","adv train loss: 0.15522445464034876 train acc: 0.9536666870117188\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2730 - accuracy: 0.9158 - val_loss: 0.1412 - val_accuracy: 0.9580\n","adv train loss: 0.14933452184001605 train acc: 0.9560666680335999\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.2620 - accuracy: 0.9214 - val_loss: 0.1314 - val_accuracy: 0.9612\n","adv train loss: 0.1490524532566468 train acc: 0.956333339214325\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.2573 - accuracy: 0.9227 - val_loss: 0.1395 - val_accuracy: 0.9567\n","adv train loss: 0.14563745474318662 train acc: 0.9580000042915344\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 42us/sample - loss: 0.2639 - accuracy: 0.9206 - val_loss: 0.1324 - val_accuracy: 0.9588\n","adv train loss: 0.14193869857589403 train acc: 0.9578333497047424\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.2535 - accuracy: 0.9230 - val_loss: 0.1403 - val_accuracy: 0.9561\n","adv train loss: 0.1488127279818058 train acc: 0.9555666446685791\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2640 - accuracy: 0.9189 - val_loss: 0.1358 - val_accuracy: 0.9570\n","adv train loss: 0.1459665158390999 train acc: 0.9581999778747559\n"]}],"source":["train_pgd(model_pgd, num_epochs, alpha)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6546,"status":"ok","timestamp":1689898314935,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"boN7aeGwbphD","outputId":"f2e778b2-0803-4796-a22e-7f21bb9282c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.1402775631153956, 0.9617]\n","Adv model:\n","[0.1358160742379725, 0.957]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[30.704048516845702, 0.0203]\n","Adv model:\n","[3.211679522705078, 0.2333]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[9.01954021911621, 0.1164]\n","Adv model:\n","[15.926033908081054, 0.0269]\n"]}],"source":["evaluate(model, model_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3294,"status":"ok","timestamp":1689898318225,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"PCJO-dfxbphD","outputId":"3b662ba1-19c5-407f-83b1-7a66ab597660"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.1402775631153956\n","Test accuracy: 0.9617\n","Model: \"mnist-simple-cnn-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv_1 (Conv2D)             (None, 26, 26, 4)         40        \n","                                                                 \n"," conv_2 (Conv2D)             (None, 13, 13, 4)         68        \n","                                                                 \n"," flatten_9 (Flatten)         (None, 676)               0         \n","                                                                 \n"," dense (Dense)               (None, 20)                13540     \n","                                                                 \n"," logit (Dense)               (None, 10)                210       \n","                                                                 \n","=================================================================\n","Total params: 13,858\n","Trainable params: 13,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.1358160742379725\n","Test accuracy: 0.957\n","Model: \"mnist-simple-cnn-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_11 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv_1 (Conv2D)             (None, 26, 26, 4)         40        \n","                                                                 \n"," conv_2 (Conv2D)             (None, 13, 13, 4)         68        \n","                                                                 \n"," flatten_10 (Flatten)        (None, 676)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                13540     \n","                                                                 \n"," logit (Dense)               (None, 10)                210       \n","                                                                 \n","=================================================================\n","Total params: 13,858\n","Trainable params: 13,858\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["eval_and_save(model)\n","eval_and_save(model_pgd)"]},{"cell_type":"markdown","metadata":{"id":"ey2hTv36haIN"},"source":["cnn-sota"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O96HoAYihaIW"},"outputs":[],"source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83035,"status":"ok","timestamp":1689543960289,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"6m7iQVXzhaIW","outputId":"aaafa732-2aed-4a05-9135-d45162aec5d8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9254"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 12s 192us/sample - loss: 0.2401 - accuracy: 0.9254 - val_loss: 0.0422 - val_accuracy: 0.9859\n","Epoch 2/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.0367 - val_accuracy: 0.9889\n","Epoch 3/20\n","60000/60000 [==============================] - 4s 60us/sample - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 4/20\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.0236 - val_accuracy: 0.9932\n","Epoch 5/20\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0257 - val_accuracy: 0.9925\n","Epoch 6/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0272 - val_accuracy: 0.9931\n","Epoch 7/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0266 - val_accuracy: 0.9927\n","Epoch 8/20\n","60000/60000 [==============================] - 4s 70us/sample - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0202 - val_accuracy: 0.9932\n","Epoch 9/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0208 - val_accuracy: 0.9941\n","Epoch 10/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0213 - val_accuracy: 0.9938\n","Epoch 11/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0213 - val_accuracy: 0.9943\n","Epoch 12/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9925\n","Epoch 13/20\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9954\n","Epoch 14/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0231 - val_accuracy: 0.9937\n","Epoch 15/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0239 - val_accuracy: 0.9940\n","Epoch 16/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0238 - val_accuracy: 0.9944\n","Epoch 17/20\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0248 - val_accuracy: 0.9940\n","Epoch 18/20\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0260 - val_accuracy: 0.9939\n","Epoch 19/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0249 - val_accuracy: 0.9948\n","Epoch 20/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0251 - val_accuracy: 0.9947\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f7f89a01390>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# normally trained model for comparision\n","\n","inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-sota-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HG6_QcwRhaIW"},"outputs":[],"source":["# model for adversarial training with pgd\n","inputs = Input(shape=(32, 32, 3))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='gtsrb-sota-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":932281,"status":"ok","timestamp":1689544974813,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"gldh00dJq9jC","outputId":"9a4dce03-3be3-4d7c-866d-4c4b4408dee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","59904/60000 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9265"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"name":"stdout","output_type":"stream","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 4s 72us/sample - loss: 0.2336 - accuracy: 0.9266 - val_loss: 0.0420 - val_accuracy: 0.9869\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"name":"stdout","output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.0300 - val_accuracy: 0.9901\n","adv train loss: 0.030231569734541698 train acc: 0.9902999997138977\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 68us/sample - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.0230 - val_accuracy: 0.9928\n","adv train loss: 0.02148217306341588 train acc: 0.9935666918754578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0208 - val_accuracy: 0.9931\n","adv train loss: 0.016763980462714486 train acc: 0.9946666955947876\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 5s 75us/sample - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.0238 - val_accuracy: 0.9920\n","adv train loss: 0.01356623228554769 train acc: 0.9959666728973389\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0219 - val_accuracy: 0.9935\n","adv train loss: 0.010391815545233355 train acc: 0.9966999888420105\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.0174 - val_accuracy: 0.9945\n","adv train loss: 0.008811341035453613 train acc: 0.9973333477973938\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0173 - val_accuracy: 0.9948\n","adv train loss: 0.007857911233859583 train acc: 0.9976000189781189\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.0207 - val_accuracy: 0.9939\n","adv train loss: 0.008768473670242626 train acc: 0.9978333115577698\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 64us/sample - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.0208 - val_accuracy: 0.9940\n","adv train loss: 0.010103383167441159 train acc: 0.9968666434288025\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9929\n","adv train loss: 0.006660927428381789 train acc: 0.9977666735649109\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0194 - val_accuracy: 0.9935\n","adv train loss: 0.005941494244543234 train acc: 0.9983333349227905\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9932\n","adv train loss: 0.004772425332066632 train acc: 0.9988999962806702\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0189 - val_accuracy: 0.9950\n","adv train loss: 0.005282013006851533 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0239 - val_accuracy: 0.9936\n","adv train loss: 0.005373753127626939 train acc: 0.9983999729156494\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0217 - val_accuracy: 0.9943\n","adv train loss: 0.004660386360459112 train acc: 0.9986333250999451\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0260 - val_accuracy: 0.9936\n","adv train loss: 0.004079835508772582 train acc: 0.9987333416938782\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0197 - val_accuracy: 0.9950\n","adv train loss: 0.004502995672669325 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9942\n","adv train loss: 0.0027133517270314616 train acc: 0.9993000030517578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9944\n","adv train loss: 0.005036794815134393 train acc: 0.9984999895095825\n"]}],"source":["train_pgd(model_pgd, num_epochs, alpha)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9236,"status":"ok","timestamp":1689544985681,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"nL56w7ZkrFAX","outputId":"fa4178ab-66c9-4866-a349-44cb1c4bd6c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.025107924216459982, 0.9947]\n","Adv model:\n","[0.02079905009451977, 0.9944]\n","\n","Test loss and accuracy on adv samples from regular model:\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"name":"stdout","output_type":"stream","text":["Regular model:\n","[2.2156280811309816, 0.5203]\n","Adv model:\n","[0.6746757946014404, 0.7902]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[0.32085431804656983, 0.902]\n","Adv model:\n","[1.0280582367897033, 0.7158]\n"]}],"source":["evaluate(model, model_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1458,"status":"ok","timestamp":1689544987128,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"Q5GrvQB3q_Zx","outputId":"3861166d-fe76-4394-f1e8-9cdc827fd8d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.025107924216459982\n","Test accuracy: 0.9947\n","Model: \"mnist-sota-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 200)               205000    \n","                                                                 \n"," dropout (Dropout)           (None, 200)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.02079905009451977\n","Test accuracy: 0.9944\n","Model: \"mnist-sota-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               205000    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 200)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["eval_and_save(model)\n","eval_and_save(model_pgd)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r6KaVFwUrL_S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"448L8e9drMCm"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_VAqMDiEtE_S"},"outputs":[],"source":["inp = Input(shape=(32, 32, 3))\n","x = Flatten()(inp)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","\n","model_test = tf.keras.Model(inputs=inp, outputs=x)\n","model_test.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),\n","              metrics=['accuracy'])\n","\n","art_model_test = KerasClassifier(model=model, clip_values=(0, 1))\n","mini_batch_size = 50\n","pgd_attack = ProjectedGradientDescent(art_model_test,\n","                                      eps=0.1,\n","                                      eps_step=0.005,\n","                                      max_iter=40,\n","                                      batch_size=mini_batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["94df444328054527a1b644d07d53e2b9","748e7f3e4a964cacb6596c3e5f9aeb00","cd031a2ed3e045caa122c75e990b9c76","b4db8c95cec94184bb6c418a36b1bb88","b50ceef5084f4e8fbd7ef1236c20aff2","3ac20f8de3d0454c90e8a3051239e025","b8554873bf6b47399285c6c388c32d34","a48c8d11979a42eebe6d1fdc8445d5b1","1a8c451d35d243f1be2316ca44e2d9e4","6deb89426dcc4376adfd194ca4cccf67","a5a03885f12c4442a4787aadf7babebf","e1dc7d9add2e49b29674756df3526495","0dd7c1300aed4ceeb1682b2915aa554d","388c902bfdeb4e379eebcca096d724b1","eddc106ce49c42419455860a20f5e7f1","875c90c6c7934f9b80871cf69832ba1d","b1e20d8339bf4197b6948840c3925646","23524757da7c4966b950065e3f4551d0","a0ab84cd7cbd4ec88ccf1a8a89f912de","f94fd5ed117f477eac807cd9bce9e768","6fd5433880cf41e48777cc9d3a870ba5","9567c77d47a24d44bde26cbba54b4b64"]},"executionInfo":{"elapsed":1067,"status":"ok","timestamp":1689281556463,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"},"user_tz":420},"id":"RdaXwIl0q9Mo","outputId":"d377b918-1d15-4d90-ad49-dc77210e6f76"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"94df444328054527a1b644d07d53e2b9","version_major":2,"version_minor":0},"text/plain":["PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1dc7d9add2e49b29674756df3526495","version_major":2,"version_minor":0},"text/plain":["PGD - Iterations:   0%|          | 0/40 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[-24.668528]\n"]},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["adv = pgd_attack.generate(x_train[:10], batch_size=32)\n","plot_figure(adv[0], cmap='gray')\n","plot_figure(x_train[0], cmap='gray')\n","print(sum(sum(x_train[0] - adv[0])))"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1loa5QTUmtNnWeL2ELnN-geJS5a2iGiW3","authorship_tag":"ABX9TyMhPg90VKISQAJDIaUbXrk4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0dd7c1300aed4ceeb1682b2915aa554d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e20d8339bf4197b6948840c3925646","placeholder":"​","style":"IPY_MODEL_23524757da7c4966b950065e3f4551d0","value":"PGD - Iterations:  52%"}},"1a8c451d35d243f1be2316ca44e2d9e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23524757da7c4966b950065e3f4551d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"388c902bfdeb4e379eebcca096d724b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0ab84cd7cbd4ec88ccf1a8a89f912de","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f94fd5ed117f477eac807cd9bce9e768","value":40}},"3ac20f8de3d0454c90e8a3051239e025":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6deb89426dcc4376adfd194ca4cccf67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fd5433880cf41e48777cc9d3a870ba5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748e7f3e4a964cacb6596c3e5f9aeb00":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac20f8de3d0454c90e8a3051239e025","placeholder":"​","style":"IPY_MODEL_b8554873bf6b47399285c6c388c32d34","value":"PGD - Random Initializations: 100%"}},"875c90c6c7934f9b80871cf69832ba1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"94df444328054527a1b644d07d53e2b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_748e7f3e4a964cacb6596c3e5f9aeb00","IPY_MODEL_cd031a2ed3e045caa122c75e990b9c76","IPY_MODEL_b4db8c95cec94184bb6c418a36b1bb88"],"layout":"IPY_MODEL_b50ceef5084f4e8fbd7ef1236c20aff2"}},"9567c77d47a24d44bde26cbba54b4b64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0ab84cd7cbd4ec88ccf1a8a89f912de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a48c8d11979a42eebe6d1fdc8445d5b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a03885f12c4442a4787aadf7babebf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b1e20d8339bf4197b6948840c3925646":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4db8c95cec94184bb6c418a36b1bb88":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6deb89426dcc4376adfd194ca4cccf67","placeholder":"​","style":"IPY_MODEL_a5a03885f12c4442a4787aadf7babebf","value":" 1/1 [00:00&lt;00:00,  2.68it/s]"}},"b50ceef5084f4e8fbd7ef1236c20aff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8554873bf6b47399285c6c388c32d34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd031a2ed3e045caa122c75e990b9c76":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48c8d11979a42eebe6d1fdc8445d5b1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a8c451d35d243f1be2316ca44e2d9e4","value":1}},"e1dc7d9add2e49b29674756df3526495":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dd7c1300aed4ceeb1682b2915aa554d","IPY_MODEL_388c902bfdeb4e379eebcca096d724b1","IPY_MODEL_eddc106ce49c42419455860a20f5e7f1"],"layout":"IPY_MODEL_875c90c6c7934f9b80871cf69832ba1d"}},"eddc106ce49c42419455860a20f5e7f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fd5433880cf41e48777cc9d3a870ba5","placeholder":"​","style":"IPY_MODEL_9567c77d47a24d44bde26cbba54b4b64","value":" 21/40 [00:00&lt;00:00, 97.01it/s]"}},"f94fd5ed117f477eac807cd9bce9e768":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}