{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1loa5QTUmtNnWeL2ELnN-geJS5a2iGiW3","authorship_tag":"ABX9TyN6ZxbTx8Qc24n7ll2SA2HB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"94df444328054527a1b644d07d53e2b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_748e7f3e4a964cacb6596c3e5f9aeb00","IPY_MODEL_cd031a2ed3e045caa122c75e990b9c76","IPY_MODEL_b4db8c95cec94184bb6c418a36b1bb88"],"layout":"IPY_MODEL_b50ceef5084f4e8fbd7ef1236c20aff2"}},"748e7f3e4a964cacb6596c3e5f9aeb00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac20f8de3d0454c90e8a3051239e025","placeholder":"​","style":"IPY_MODEL_b8554873bf6b47399285c6c388c32d34","value":"PGD - Random Initializations: 100%"}},"cd031a2ed3e045caa122c75e990b9c76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48c8d11979a42eebe6d1fdc8445d5b1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a8c451d35d243f1be2316ca44e2d9e4","value":1}},"b4db8c95cec94184bb6c418a36b1bb88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6deb89426dcc4376adfd194ca4cccf67","placeholder":"​","style":"IPY_MODEL_a5a03885f12c4442a4787aadf7babebf","value":" 1/1 [00:00&lt;00:00,  2.68it/s]"}},"b50ceef5084f4e8fbd7ef1236c20aff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ac20f8de3d0454c90e8a3051239e025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8554873bf6b47399285c6c388c32d34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a48c8d11979a42eebe6d1fdc8445d5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8c451d35d243f1be2316ca44e2d9e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6deb89426dcc4376adfd194ca4cccf67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a03885f12c4442a4787aadf7babebf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1dc7d9add2e49b29674756df3526495":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dd7c1300aed4ceeb1682b2915aa554d","IPY_MODEL_388c902bfdeb4e379eebcca096d724b1","IPY_MODEL_eddc106ce49c42419455860a20f5e7f1"],"layout":"IPY_MODEL_875c90c6c7934f9b80871cf69832ba1d"}},"0dd7c1300aed4ceeb1682b2915aa554d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e20d8339bf4197b6948840c3925646","placeholder":"​","style":"IPY_MODEL_23524757da7c4966b950065e3f4551d0","value":"PGD - Iterations:  52%"}},"388c902bfdeb4e379eebcca096d724b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0ab84cd7cbd4ec88ccf1a8a89f912de","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f94fd5ed117f477eac807cd9bce9e768","value":40}},"eddc106ce49c42419455860a20f5e7f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fd5433880cf41e48777cc9d3a870ba5","placeholder":"​","style":"IPY_MODEL_9567c77d47a24d44bde26cbba54b4b64","value":" 21/40 [00:00&lt;00:00, 97.01it/s]"}},"875c90c6c7934f9b80871cf69832ba1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b1e20d8339bf4197b6948840c3925646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23524757da7c4966b950065e3f4551d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0ab84cd7cbd4ec88ccf1a8a89f912de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f94fd5ed117f477eac807cd9bce9e768":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fd5433880cf41e48777cc9d3a870ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9567c77d47a24d44bde26cbba54b4b64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install tensorflow_ranking\n","!pip install adversarial-robustness-toolbox\n","!pip uninstall numpy\n","!pip install numpy==1.23.5\n","!pip install keras==2.12\n","!pip install tensorflow-serving-api==2.12.0\n","!pip install tensorflow==2.12"],"metadata":{"id":"N1rr9uiletu0","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1689893290033,"user_tz":420,"elapsed":189214,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"6749fd66-0e41-4f1a-b800-ad31644e14d4"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow_ranking in /usr/local/lib/python3.10/dist-packages (0.5.2)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.4.0)\n","Collecting numpy==1.23.2 (from tensorflow_ranking)\n","  Using cached numpy-1.23.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (1.16.0)\n","Requirement already satisfied: tensorflow-serving-api<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_ranking) (2.12.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.56.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.20.3)\n","Collecting tensorflow<3,>=2.12.1 (from tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Using cached tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.6.3)\n","Collecting flatbuffers>=23.1.21 (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.8.0)\n","Collecting keras<2.14,>=2.13.1 (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (16.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (23.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (67.7.2)\n","Collecting tensorboard<2.14,>=2.13 (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n","Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking)\n","  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.3.6)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.1->tensorflow-serving-api<3.0.0,>=2.0.0->tensorflow_ranking) (3.2.2)\n","Installing collected packages: flatbuffers, tensorflow-estimator, numpy, keras, tensorboard, tensorflow\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0.7\n","    Uninstalling flatbuffers-2.0.7:\n","      Successfully uninstalled flatbuffers-2.0.7\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.12.0\n","    Uninstalling tensorflow-estimator-2.12.0:\n","      Successfully uninstalled tensorflow-estimator-2.12.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.12.0\n","    Uninstalling keras-2.12.0:\n","      Successfully uninstalled keras-2.12.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.12.3\n","    Uninstalling tensorboard-2.12.3:\n","      Successfully uninstalled tensorboard-2.12.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.12.0\n","    Uninstalling tensorflow-2.12.0:\n","      Successfully uninstalled tensorflow-2.12.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf2onnx 1.14.0 requires flatbuffers<3.0,>=1.12, but you have flatbuffers 23.5.26 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed flatbuffers-23.5.26 keras-2.13.1 numpy-1.23.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["flatbuffers","keras","numpy","tensorboard","tensorflow","tensorflow_estimator"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.10/dist-packages (1.15.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.23.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.10.1)\n","Requirement already satisfied: scikit-learn<1.2.0,>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.65.0)\n","Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (1.3.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.2.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n","Found existing installation: numpy 1.23.2\n","Uninstalling numpy-1.23.2:\n","  Would remove:\n","    /usr/local/bin/f2py\n","    /usr/local/bin/f2py3\n","    /usr/local/bin/f2py3.10\n","    /usr/local/lib/python3.10/dist-packages/numpy-1.23.2.dist-info/*\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\n","    /usr/local/lib/python3.10/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.10/dist-packages/numpy/*\n","Proceed (Y/n)? y\n","  Successfully uninstalled numpy-1.23.2\n","Collecting numpy==1.23.5\n","  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Installing collected packages: numpy\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-ranking 0.5.2 requires numpy==1.23.2, but you have numpy 1.23.5 which is incompatible.\n","tf2onnx 1.14.0 requires flatbuffers<3.0,>=1.12, but you have flatbuffers 23.5.26 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"code","execution_count":18,"metadata":{"id":"5H9Rz649er0f","executionInfo":{"status":"ok","timestamp":1689894642979,"user_tz":420,"elapsed":1201,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["from tensorflow import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Input, Dense, Reshape, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n","from keras.initializers import GlorotUniform\n","import tensorflow as tf\n","import tensorflow_ranking as tfr\n","import tf2onnx\n","import numpy as np\n","from art.estimators.classification import KerasClassifier\n","from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent"]},{"cell_type":"code","source":["import sys\n","sys.path.append(sys.path.append('/content/drive/My Drive/CURIS/VeriX/train_networks'))"],"metadata":{"id":"DLBIohSmB0q_","executionInfo":{"status":"ok","timestamp":1689894428247,"user_tz":420,"elapsed":5,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NV-yxKvdgV07","executionInfo":{"status":"ok","timestamp":1689894430810,"user_tz":420,"elapsed":2567,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"7044df45-11c4-49a0-b0ef-f6f19b04fb72"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"7vdrHaqPmF3d","executionInfo":{"status":"ok","timestamp":1689894430811,"user_tz":420,"elapsed":6,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["SEED = 137\n","output_path = 'drive/MyDrive/CURIS/VeriX/networks/'"],"metadata":{"id":"SBuoH7amV0RX","executionInfo":{"status":"ok","timestamp":1689894430811,"user_tz":420,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255"],"metadata":{"id":"X1ZbugoifOQL","executionInfo":{"status":"ok","timestamp":1689894431260,"user_tz":420,"elapsed":452,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","def plot_figure(image, path=None, cmap=None):\n","    fig = plt.figure()\n","    ax = plt.Axes(fig, [-0.5, -0.5, 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    plt.imshow(image, cmap=cmap)\n","    if path is not None:\n","      plt.savefig(path, bbox_inches='tight')\n","    # plt.close(fig)"],"metadata":{"id":"TJij4mzOg34b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_and_save(model):\n","  score = model.evaluate(x_test, y_test, verbose=0)\n","  print(\"Test loss:\", score[0])\n","  print(\"Test accuracy:\", score[1])\n","  model.summary()\n","  model.save(output_path + model.name + '.h5')\n","  # model_proto, _ = tf2onnx.convert.from_keras(model, output_path=output_path + model.name + '.onnx')"],"metadata":{"id":"1xIYjKSw4rC1","executionInfo":{"status":"ok","timestamp":1689895569366,"user_tz":420,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def print_weights(model):\n","  for layer in model.layers:\n","    print(layer.get_config())\n","    print(layer.get_weights())"],"metadata":{"id":"eDilkggLVqLk","executionInfo":{"status":"ok","timestamp":1689887492184,"user_tz":420,"elapsed":2,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train_pgd(model_pgd, num_epochs, alpha):\n","  art_model_pgd = KerasClassifier(model_pgd, clip_values=(0, 1))\n","  art_model_pgd.fit(x_train, y_train,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","  pgd_attack = ProjectedGradientDescent(art_model_pgd, eps=0.1, eps_step=0.01, max_iter=10, verbose=False)\n","\n","  num_samples = len(x_train)\n","  num_adv = int(num_samples * alpha)\n","  num_real = num_samples - num_adv\n","\n","  for i in range(num_epochs - 1):\n","    adv_indices = np.random.choice(x_train.shape[0], size=num_adv, replace=False)\n","    real_indices = np.random.choice(x_train.shape[0], size=num_real, replace=False)\n","    adv_samples = pgd_attack.generate(\n","        x_train[adv_indices],\n","        batch_size=128)\n","    x_real = x_train[real_indices]\n","    y_real = y_train[real_indices]\n","    x_adv = np.concatenate((adv_samples, x_real))\n","    y_adv = np.concatenate((y_train[adv_indices], y_real))\n","    permutation = np.random.permutation(num_samples)\n","    x_adv = x_adv[permutation]\n","    y_adv = y_adv[permutation]\n","    art_model_pgd.fit(x_adv, y_adv,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","    score = model_pgd.evaluate(adv_samples, y_train[adv_indices])\n","    print(f'adv train loss: {score[0]} train acc: {score[1]}')"],"metadata":{"id":"KOOgHT0NXFkU","executionInfo":{"status":"ok","timestamp":1689895461108,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, model_adv):\n","  print('Test loss and accuracy on original test data:')\n","  print('Regular model:')\n","  print(model.evaluate(x_test, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(x_test, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from regular model:')\n","  art_model_regular_pgd = KerasClassifier(model, clip_values=(0, 1))\n","  # pgd_attack_regular = ProjectedGradientDescent(art_model_regular_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_regular.generate(x_test, batch_size=128)\n","  fgm_attack_regular = FastGradientMethod(art_model_regular_pgd)\n","  adv = fgm_attack_regular.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from adv model:')\n","  art_model_adv_pgd = KerasClassifier(model_adv, clip_values=(0, 1))\n","  # pgd_attack_adv = ProjectedGradientDescent(art_model_adv_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_adv.generate(x_test, batch_size=128)\n","  fgm_attack_adv = FastGradientMethod(art_model_adv_pgd)\n","  adv = fgm_attack_adv.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))"],"metadata":{"id":"1qWWSKdVxury","executionInfo":{"status":"ok","timestamp":1689895664600,"user_tz":420,"elapsed":839,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SVzgmf_VZ3a0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10x2 fully connected"],"metadata":{"id":"mNzV_fNFZ3zx"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689895708614,"user_tz":420,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"hpVnc6g7Z3zx"},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-10x2-normal')\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGV3hmlSZ3zy","executionInfo":{"status":"ok","timestamp":1689895739513,"user_tz":420,"elapsed":30901,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"bbddaf44-f3d0-47ed-8882-2a021b43eb8c"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.8568 - accuracy: 0.7497 - val_loss: 0.4422 - val_accuracy: 0.8704\n","Epoch 2/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.3886 - accuracy: 0.8885 - val_loss: 0.3421 - val_accuracy: 0.9017\n","Epoch 3/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.3279 - accuracy: 0.9059 - val_loss: 0.3061 - val_accuracy: 0.9132\n","Epoch 4/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2962 - accuracy: 0.9162 - val_loss: 0.2836 - val_accuracy: 0.9188\n","Epoch 5/20\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.2739 - accuracy: 0.9230 - val_loss: 0.2630 - val_accuracy: 0.9238\n","Epoch 6/20\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.2573 - accuracy: 0.9266 - val_loss: 0.2558 - val_accuracy: 0.9259\n","Epoch 7/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.2454 - accuracy: 0.9296 - val_loss: 0.2450 - val_accuracy: 0.9275\n","Epoch 8/20\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.2367 - accuracy: 0.9311 - val_loss: 0.2373 - val_accuracy: 0.9318\n","Epoch 9/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.2279 - accuracy: 0.9347 - val_loss: 0.2312 - val_accuracy: 0.9325\n","Epoch 10/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.2219 - accuracy: 0.9359 - val_loss: 0.2310 - val_accuracy: 0.9331\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.2158 - accuracy: 0.9373 - val_loss: 0.2249 - val_accuracy: 0.9337\n","Epoch 12/20\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.2113 - accuracy: 0.9395 - val_loss: 0.2235 - val_accuracy: 0.9337\n","Epoch 13/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2066 - accuracy: 0.9408 - val_loss: 0.2246 - val_accuracy: 0.9327\n","Epoch 14/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2025 - accuracy: 0.9415 - val_loss: 0.2130 - val_accuracy: 0.9367\n","Epoch 15/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1991 - accuracy: 0.9427 - val_loss: 0.2119 - val_accuracy: 0.9374\n","Epoch 16/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1955 - accuracy: 0.9431 - val_loss: 0.2149 - val_accuracy: 0.9373\n","Epoch 17/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1931 - accuracy: 0.9441 - val_loss: 0.2078 - val_accuracy: 0.9390\n","Epoch 18/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1900 - accuracy: 0.9454 - val_loss: 0.2097 - val_accuracy: 0.9391\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1871 - accuracy: 0.9462 - val_loss: 0.2077 - val_accuracy: 0.9394\n","Epoch 20/20\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.1852 - accuracy: 0.9459 - val_loss: 0.2128 - val_accuracy: 0.9395\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc7780be4a0>"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-10x2-pgd')\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689895613317,"user_tz":420,"elapsed":1227,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"pn3jCiT4Z3zy"},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwAsxafqKb9u","executionInfo":{"status":"ok","timestamp":1689896324334,"user_tz":420,"elapsed":584823,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"e7a06b90-1eec-4645-e712-eca3e666218d"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.3376 - accuracy: 0.9051 - val_loss: 0.3061 - val_accuracy: 0.9147\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.5151 - accuracy: 0.8595 - val_loss: 0.2961 - val_accuracy: 0.9169\n","adv train loss: 0.3165614689906438 train acc: 0.9095333218574524\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.4866 - accuracy: 0.8609 - val_loss: 0.2833 - val_accuracy: 0.9198\n","adv train loss: 0.3127591758966446 train acc: 0.9099000096321106\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4684 - accuracy: 0.8670 - val_loss: 0.2754 - val_accuracy: 0.9214\n","adv train loss: 0.33213509452740353 train acc: 0.9035666584968567\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.4566 - accuracy: 0.8660 - val_loss: 0.2674 - val_accuracy: 0.9262\n","adv train loss: 0.32522298869689303 train acc: 0.9080666899681091\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4449 - accuracy: 0.8688 - val_loss: 0.2628 - val_accuracy: 0.9237\n","adv train loss: 0.32239827243884406 train acc: 0.9061333537101746\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.4430 - accuracy: 0.8691 - val_loss: 0.2607 - val_accuracy: 0.9257\n","adv train loss: 0.31339082714716593 train acc: 0.9088000059127808\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4505 - accuracy: 0.8660 - val_loss: 0.2651 - val_accuracy: 0.9229\n","adv train loss: 0.3263106398026148 train acc: 0.9031999707221985\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.4501 - accuracy: 0.8634 - val_loss: 0.2565 - val_accuracy: 0.9278\n","adv train loss: 0.3209573263565699 train acc: 0.9068333506584167\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4412 - accuracy: 0.8662 - val_loss: 0.2549 - val_accuracy: 0.9270\n","adv train loss: 0.31760936699708303 train acc: 0.9061999917030334\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.4420 - accuracy: 0.8670 - val_loss: 0.2561 - val_accuracy: 0.9260\n","adv train loss: 0.3139762287100156 train acc: 0.9089666604995728\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.4404 - accuracy: 0.8665 - val_loss: 0.2521 - val_accuracy: 0.9280\n","adv train loss: 0.3209549914201101 train acc: 0.9063000082969666\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4395 - accuracy: 0.8652 - val_loss: 0.2514 - val_accuracy: 0.9264\n","adv train loss: 0.30831986566384634 train acc: 0.9096666574478149\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.4484 - accuracy: 0.8662 - val_loss: 0.2494 - val_accuracy: 0.9293\n","adv train loss: 0.3189833078185717 train acc: 0.9067999720573425\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4344 - accuracy: 0.8673 - val_loss: 0.2460 - val_accuracy: 0.9281\n","adv train loss: 0.3077023071606954 train acc: 0.9074666500091553\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.4413 - accuracy: 0.8653 - val_loss: 0.2522 - val_accuracy: 0.9278\n","adv train loss: 0.3259435512423515 train acc: 0.9027000069618225\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4316 - accuracy: 0.8682 - val_loss: 0.2490 - val_accuracy: 0.9293\n","adv train loss: 0.30987904504537583 train acc: 0.9071333408355713\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4451 - accuracy: 0.8665 - val_loss: 0.2466 - val_accuracy: 0.9295\n","adv train loss: 0.3244559766928355 train acc: 0.90420001745224\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4360 - accuracy: 0.8660 - val_loss: 0.2452 - val_accuracy: 0.9302\n","adv train loss: 0.3046146858930588 train acc: 0.9098333120346069\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4374 - accuracy: 0.8651 - val_loss: 0.2479 - val_accuracy: 0.9285\n","adv train loss: 0.3227664453466733 train acc: 0.9035999774932861\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689896329185,"user_tz":420,"elapsed":4864,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"8a9af28a-0c77-4365-dfc0-ac164953d37a","id":"bLd8L1TFZ3zy"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.21277001615911723, 0.9395]\n","Adv model:\n","[0.24793667847812176, 0.9285]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[35.520732318115236, 0.0214]\n","Adv model:\n","[5.187736444854736, 0.0859]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[17.432188684082032, 0.0472]\n","Adv model:\n","[14.042941835021972, 0.024]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YZbUPNsaDfa","executionInfo":{"status":"ok","timestamp":1689896332449,"user_tz":420,"elapsed":3275,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"5c8bc91e-e310-4530-8282-2af55a85885f"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.21277001615911723\n","Test accuracy: 0.9395\n","Model: \"mnist-10x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                7850      \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                110       \n","                                                                 \n"," logit (Dense)               (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 8,070\n","Trainable params: 8,070\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.24793667847812176\n","Test accuracy: 0.9285\n","Model: \"mnist-10x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_3 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                7850      \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                110       \n","                                                                 \n"," logit (Dense)               (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 8,070\n","Trainable params: 8,070\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["30x2 fully connected"],"metadata":{"id":"naNeO7cyZ41Q"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"id":"AuLtM1saZ41Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-30x2-normal')\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P63H5JuUZ41Q","executionInfo":{"status":"ok","timestamp":1689896364080,"user_tz":420,"elapsed":31648,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"a01e31b5-eff3-4ef8-c6de-ec0e593c8538"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.5124 - accuracy: 0.8558 - val_loss: 0.2303 - val_accuracy: 0.9347\n","Epoch 2/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.2104 - accuracy: 0.9400 - val_loss: 0.1820 - val_accuracy: 0.9447\n","Epoch 3/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.1671 - accuracy: 0.9517 - val_loss: 0.1636 - val_accuracy: 0.9515\n","Epoch 4/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1431 - accuracy: 0.9586 - val_loss: 0.1458 - val_accuracy: 0.9584\n","Epoch 5/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1269 - accuracy: 0.9628 - val_loss: 0.1337 - val_accuracy: 0.9623\n","Epoch 6/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1136 - accuracy: 0.9668 - val_loss: 0.1284 - val_accuracy: 0.9644\n","Epoch 7/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1021 - accuracy: 0.9702 - val_loss: 0.1179 - val_accuracy: 0.9673\n","Epoch 8/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0938 - accuracy: 0.9725 - val_loss: 0.1174 - val_accuracy: 0.9666\n","Epoch 9/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0862 - accuracy: 0.9746 - val_loss: 0.1192 - val_accuracy: 0.9670\n","Epoch 10/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0795 - accuracy: 0.9764 - val_loss: 0.1166 - val_accuracy: 0.9679\n","Epoch 11/20\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.0743 - accuracy: 0.9779 - val_loss: 0.1152 - val_accuracy: 0.9682\n","Epoch 12/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0692 - accuracy: 0.9796 - val_loss: 0.1088 - val_accuracy: 0.9694\n","Epoch 13/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0652 - accuracy: 0.9809 - val_loss: 0.1145 - val_accuracy: 0.9671\n","Epoch 14/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0615 - accuracy: 0.9812 - val_loss: 0.1132 - val_accuracy: 0.9693\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.1092 - val_accuracy: 0.9687\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.0534 - accuracy: 0.9841 - val_loss: 0.1129 - val_accuracy: 0.9683\n","Epoch 17/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0511 - accuracy: 0.9850 - val_loss: 0.1109 - val_accuracy: 0.9691\n","Epoch 18/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.1138 - val_accuracy: 0.9705\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0454 - accuracy: 0.9862 - val_loss: 0.1130 - val_accuracy: 0.9705\n","Epoch 20/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.1183 - val_accuracy: 0.9696\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc7707db430>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-30x2-pgd')\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689896364080,"user_tz":420,"elapsed":19,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"z4K-thMiZ41R"},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e49eda35-04e0-4a28-8d2a-8ef06946ebb2","id":"R0E4X0oyZ41R","executionInfo":{"status":"ok","timestamp":1689896957111,"user_tz":420,"elapsed":593048,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.5193 - accuracy: 0.8519 - val_loss: 0.2406 - val_accuracy: 0.9289\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.3063 - accuracy: 0.9090 - val_loss: 0.1998 - val_accuracy: 0.9429\n","adv train loss: 0.19905099148750305 train acc: 0.9410333037376404\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.3871 - accuracy: 0.8896 - val_loss: 0.1743 - val_accuracy: 0.9476\n","adv train loss: 0.19209390201965967 train acc: 0.9446333050727844\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2975 - accuracy: 0.9109 - val_loss: 0.1559 - val_accuracy: 0.9511\n","adv train loss: 0.17202934294541677 train acc: 0.9508666396141052\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.2885 - accuracy: 0.9154 - val_loss: 0.1625 - val_accuracy: 0.9530\n","adv train loss: 0.17560197636981806 train acc: 0.9499666690826416\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2717 - accuracy: 0.9204 - val_loss: 0.1442 - val_accuracy: 0.9563\n","adv train loss: 0.1654665900528431 train acc: 0.9519333243370056\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.2611 - accuracy: 0.9223 - val_loss: 0.1472 - val_accuracy: 0.9562\n","adv train loss: 0.1565645602852106 train acc: 0.9541333317756653\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2494 - accuracy: 0.9273 - val_loss: 0.1365 - val_accuracy: 0.9597\n","adv train loss: 0.15693617714842162 train acc: 0.9531999826431274\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.2494 - accuracy: 0.9266 - val_loss: 0.1336 - val_accuracy: 0.9602\n","adv train loss: 0.14930208047032356 train acc: 0.9557666778564453\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2448 - accuracy: 0.9276 - val_loss: 0.1236 - val_accuracy: 0.9619\n","adv train loss: 0.1440438701738914 train acc: 0.958133339881897\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2293 - accuracy: 0.9322 - val_loss: 0.1305 - val_accuracy: 0.9609\n","adv train loss: 0.1347216648971041 train acc: 0.9614999890327454\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2263 - accuracy: 0.9333 - val_loss: 0.1228 - val_accuracy: 0.9613\n","adv train loss: 0.13829342662443717 train acc: 0.959933340549469\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2278 - accuracy: 0.9334 - val_loss: 0.1219 - val_accuracy: 0.9631\n","adv train loss: 0.13267858478426933 train acc: 0.9609000086784363\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.2241 - accuracy: 0.9340 - val_loss: 0.1186 - val_accuracy: 0.9659\n","adv train loss: 0.131904685048759 train acc: 0.9604666829109192\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2191 - accuracy: 0.9347 - val_loss: 0.1157 - val_accuracy: 0.9676\n","adv train loss: 0.12679241279363632 train acc: 0.9626333117485046\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.2155 - accuracy: 0.9356 - val_loss: 0.1170 - val_accuracy: 0.9647\n","adv train loss: 0.1267549774095416 train acc: 0.9623666405677795\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2154 - accuracy: 0.9355 - val_loss: 0.1179 - val_accuracy: 0.9653\n","adv train loss: 0.1250694129963716 train acc: 0.9631333351135254\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2050 - accuracy: 0.9398 - val_loss: 0.1130 - val_accuracy: 0.9659\n","adv train loss: 0.12031643474598726 train acc: 0.9634000062942505\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.2089 - accuracy: 0.9386 - val_loss: 0.1118 - val_accuracy: 0.9659\n","adv train loss: 0.12108844153285027 train acc: 0.9637666940689087\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2061 - accuracy: 0.9388 - val_loss: 0.1115 - val_accuracy: 0.9669\n","adv train loss: 0.11487848753730456 train acc: 0.9653666615486145\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689896962798,"user_tz":420,"elapsed":5709,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"4a09b169-d940-436e-db33-398477ac2b68","id":"n6YOrGfFZ41R"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.11829419829172548, 0.9696]\n","Adv model:\n","[0.11145895309951157, 0.9669]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[37.91198641357422, 0.0196]\n","Adv model:\n","[2.174595686149597, 0.4056]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[11.56554037322998, 0.1521]\n","Adv model:\n","[14.929519357299805, 0.0138]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uj7eSMGRa-K9","executionInfo":{"status":"ok","timestamp":1689896966699,"user_tz":420,"elapsed":3916,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"9b4a0478-2d81-4265-b49f-bc5d02c979e2"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.11829419829172548\n","Test accuracy: 0.9696\n","Model: \"mnist-30x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_5 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                23550     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 24,790\n","Trainable params: 24,790\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.11145895309951157\n","Test accuracy: 0.9669\n","Model: \"mnist-30x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_6 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                23550     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 24,790\n","Trainable params: 24,790\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["100x2 fully connected"],"metadata":{"id":"6VVT-pBU6xbD"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"id":"EX0g9sERb6uD","executionInfo":{"status":"ok","timestamp":1689887468292,"user_tz":420,"elapsed":1134,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-100x2-normal')\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"id":"oURqqMajArni","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689897000768,"user_tz":420,"elapsed":34088,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"7c93a154-9862-40e4-a724-e78a093e3975"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.3409 - accuracy: 0.9020 - val_loss: 0.1795 - val_accuracy: 0.9455\n","Epoch 2/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1399 - accuracy: 0.9587 - val_loss: 0.1216 - val_accuracy: 0.9630\n","Epoch 3/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0978 - accuracy: 0.9704 - val_loss: 0.1003 - val_accuracy: 0.9675\n","Epoch 4/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0749 - accuracy: 0.9771 - val_loss: 0.0893 - val_accuracy: 0.9709\n","Epoch 5/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0593 - accuracy: 0.9819 - val_loss: 0.0879 - val_accuracy: 0.9726\n","Epoch 6/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0482 - accuracy: 0.9843 - val_loss: 0.0891 - val_accuracy: 0.9731\n","Epoch 7/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0391 - accuracy: 0.9884 - val_loss: 0.0829 - val_accuracy: 0.9746\n","Epoch 8/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0878 - val_accuracy: 0.9727\n","Epoch 9/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.0281 - accuracy: 0.9916 - val_loss: 0.0824 - val_accuracy: 0.9761\n","Epoch 10/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.0232 - accuracy: 0.9931 - val_loss: 0.0870 - val_accuracy: 0.9764\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1020 - val_accuracy: 0.9728\n","Epoch 12/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0956 - val_accuracy: 0.9734\n","Epoch 13/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0886 - val_accuracy: 0.9775\n","Epoch 14/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.0922 - val_accuracy: 0.9768\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0949 - val_accuracy: 0.9766\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.1032 - val_accuracy: 0.9755\n","Epoch 17/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1317 - val_accuracy: 0.9709\n","Epoch 18/20\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1117 - val_accuracy: 0.9754\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.1143 - val_accuracy: 0.9761\n","Epoch 20/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.1072 - val_accuracy: 0.9769\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc7705c2f50>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-100x2-pgd')\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"CaPQ3vFIfSZQ","executionInfo":{"status":"ok","timestamp":1689897000768,"user_tz":420,"elapsed":15,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTxLq2rZX086","executionInfo":{"status":"ok","timestamp":1689897598465,"user_tz":420,"elapsed":597711,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"33a8a113-fc4e-4dc2-ae0f-5ecdc6bf993b"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 38us/sample - loss: 0.3485 - accuracy: 0.8993 - val_loss: 0.1720 - val_accuracy: 0.9490\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2155 - accuracy: 0.9358 - val_loss: 0.1238 - val_accuracy: 0.9623\n","adv train loss: 0.11473088092257579 train acc: 0.9653000235557556\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.2434 - accuracy: 0.9307 - val_loss: 0.1162 - val_accuracy: 0.9643\n","adv train loss: 0.10867337775677442 train acc: 0.9684000015258789\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1843 - accuracy: 0.9484 - val_loss: 0.0990 - val_accuracy: 0.9704\n","adv train loss: 0.09152162838528553 train acc: 0.972599983215332\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1614 - accuracy: 0.9539 - val_loss: 0.0952 - val_accuracy: 0.9706\n","adv train loss: 0.08296541338587801 train acc: 0.9761999845504761\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1579 - accuracy: 0.9548 - val_loss: 0.0928 - val_accuracy: 0.9699\n","adv train loss: 0.07537264022231102 train acc: 0.9778000116348267\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1444 - accuracy: 0.9592 - val_loss: 0.0841 - val_accuracy: 0.9738\n","adv train loss: 0.06622250464372337 train acc: 0.9799000024795532\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1376 - accuracy: 0.9608 - val_loss: 0.0896 - val_accuracy: 0.9716\n","adv train loss: 0.06873930878937244 train acc: 0.9797000288963318\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1316 - accuracy: 0.9633 - val_loss: 0.0804 - val_accuracy: 0.9755\n","adv train loss: 0.06325296099297702 train acc: 0.9822333455085754\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.1302 - accuracy: 0.9633 - val_loss: 0.0832 - val_accuracy: 0.9737\n","adv train loss: 0.0614114660859108 train acc: 0.9817666411399841\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1268 - accuracy: 0.9642 - val_loss: 0.0768 - val_accuracy: 0.9766\n","adv train loss: 0.059161939499403036 train acc: 0.9833333492279053\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.1217 - accuracy: 0.9655 - val_loss: 0.0767 - val_accuracy: 0.9754\n","adv train loss: 0.05450291076426705 train acc: 0.984333336353302\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1221 - accuracy: 0.9649 - val_loss: 0.0704 - val_accuracy: 0.9779\n","adv train loss: 0.04780977053120732 train acc: 0.9866666793823242\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.1226 - accuracy: 0.9649 - val_loss: 0.0775 - val_accuracy: 0.9761\n","adv train loss: 0.05007306928460797 train acc: 0.9857000112533569\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.1263 - accuracy: 0.9654 - val_loss: 0.0749 - val_accuracy: 0.9767\n","adv train loss: 0.05070892217954 train acc: 0.9855666756629944\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1179 - accuracy: 0.9656 - val_loss: 0.0699 - val_accuracy: 0.9787\n","adv train loss: 0.04988621731524666 train acc: 0.9851333498954773\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.1159 - accuracy: 0.9671 - val_loss: 0.0671 - val_accuracy: 0.9790\n","adv train loss: 0.04297111075272163 train acc: 0.9879000186920166\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1146 - accuracy: 0.9673 - val_loss: 0.0667 - val_accuracy: 0.9776\n","adv train loss: 0.042188754510506986 train acc: 0.9880333542823792\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1125 - accuracy: 0.9687 - val_loss: 0.0673 - val_accuracy: 0.9792\n","adv train loss: 0.039338898815711336 train acc: 0.9893666505813599\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 32us/sample - loss: 0.1170 - accuracy: 0.9677 - val_loss: 0.0680 - val_accuracy: 0.9778\n","adv train loss: 0.040279233229036135 train acc: 0.987933337688446\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IpKJN3xrYJ2","executionInfo":{"status":"ok","timestamp":1689897605372,"user_tz":420,"elapsed":6926,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"51cc2f04-dbb8-4ed9-dc75-e5c99383547b"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.10720364366221183, 0.9769]\n","Adv model:\n","[0.0680444527752581, 0.9778]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[35.847421008300785, 0.0311]\n","Adv model:\n","[1.3557057939052581, 0.599]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[9.888806645202637, 0.1419]\n","Adv model:\n","[17.42983818359375, 0.0171]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"id":"qtJuakrFpRT-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689897611163,"user_tz":420,"elapsed":5808,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"98eadfd0-696a-475b-b688-8886a8be34f3"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.10720364366221183\n","Test accuracy: 0.9769\n","Model: \"mnist-100x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_8 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_7 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.0680444527752581\n","Test accuracy: 0.9778\n","Model: \"mnist-100x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_8 (Flatten)         (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"crnHiwZWri6s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cnn-simple"],"metadata":{"id":"K1HqrwdNbHAD"}},{"cell_type":"code","source":["inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=x, name='mnist-simple-cnn-normal')\n","\n","model.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUa502OLbIfq","executionInfo":{"status":"ok","timestamp":1689897651753,"user_tz":420,"elapsed":40609,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"6a7e1b36-afa9-4c5d-f76d-2b1d4e29d829"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.5132 - accuracy: 0.8463 - val_loss: 0.2605 - val_accuracy: 0.9250\n","Epoch 2/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2464 - accuracy: 0.9289 - val_loss: 0.2229 - val_accuracy: 0.9357\n","Epoch 3/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2163 - accuracy: 0.9367 - val_loss: 0.1968 - val_accuracy: 0.9431\n","Epoch 4/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1961 - accuracy: 0.9431 - val_loss: 0.1827 - val_accuracy: 0.9500\n","Epoch 5/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1795 - accuracy: 0.9478 - val_loss: 0.1795 - val_accuracy: 0.9478\n","Epoch 6/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1670 - accuracy: 0.9515 - val_loss: 0.1721 - val_accuracy: 0.9490\n","Epoch 7/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1561 - accuracy: 0.9540 - val_loss: 0.1630 - val_accuracy: 0.9525\n","Epoch 8/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.1471 - accuracy: 0.9562 - val_loss: 0.1538 - val_accuracy: 0.9554\n","Epoch 9/20\n","60000/60000 [==============================] - 2s 35us/sample - loss: 0.1409 - accuracy: 0.9584 - val_loss: 0.1536 - val_accuracy: 0.9557\n","Epoch 10/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.1337 - accuracy: 0.9601 - val_loss: 0.1473 - val_accuracy: 0.9590\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.1288 - accuracy: 0.9612 - val_loss: 0.1525 - val_accuracy: 0.9568\n","Epoch 12/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.1223 - accuracy: 0.9639 - val_loss: 0.1439 - val_accuracy: 0.9592\n","Epoch 13/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1177 - accuracy: 0.9649 - val_loss: 0.1448 - val_accuracy: 0.9595\n","Epoch 14/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1153 - accuracy: 0.9657 - val_loss: 0.1460 - val_accuracy: 0.9574\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.1114 - accuracy: 0.9662 - val_loss: 0.1365 - val_accuracy: 0.9619\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1086 - accuracy: 0.9670 - val_loss: 0.1422 - val_accuracy: 0.9609\n","Epoch 17/20\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.1051 - accuracy: 0.9682 - val_loss: 0.1418 - val_accuracy: 0.9596\n","Epoch 18/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.1023 - accuracy: 0.9688 - val_loss: 0.1346 - val_accuracy: 0.9624\n","Epoch 19/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.0998 - accuracy: 0.9691 - val_loss: 0.1391 - val_accuracy: 0.9630\n","Epoch 20/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 0.0978 - accuracy: 0.9706 - val_loss: 0.1403 - val_accuracy: 0.9617\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc770397430>"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=x, name='mnist-simple-cnn-pgd')\n","\n","model_pgd.compile(# loss='categorical_crossentropy',\n","              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"o5eUrlP7UfFp","executionInfo":{"status":"ok","timestamp":1689897653032,"user_tz":420,"elapsed":1297,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"id":"bWpstsChbnGI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689898308405,"user_tz":420,"elapsed":655379,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"e70411e5-ada4-480d-fbd1-266747351bf9"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 43us/sample - loss: 0.5137 - accuracy: 0.8450 - val_loss: 0.2625 - val_accuracy: 0.9267\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.4068 - accuracy: 0.8761 - val_loss: 0.2608 - val_accuracy: 0.9228\n","adv train loss: 0.2736689247151216 train acc: 0.9194333553314209\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.4150 - accuracy: 0.8756 - val_loss: 0.2112 - val_accuracy: 0.9388\n","adv train loss: 0.23954009110331537 train acc: 0.9315333366394043\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.4006 - accuracy: 0.8777 - val_loss: 0.2047 - val_accuracy: 0.9413\n","adv train loss: 0.2569413528243701 train acc: 0.9260333180427551\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.3544 - accuracy: 0.8907 - val_loss: 0.1912 - val_accuracy: 0.9460\n","adv train loss: 0.21969784870147704 train acc: 0.9362000226974487\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.3523 - accuracy: 0.8922 - val_loss: 0.1761 - val_accuracy: 0.9487\n","adv train loss: 0.21780159526268641 train acc: 0.9365000128746033\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.3237 - accuracy: 0.9017 - val_loss: 0.1751 - val_accuracy: 0.9482\n","adv train loss: 0.1967509552915891 train acc: 0.9445666670799255\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.3195 - accuracy: 0.9014 - val_loss: 0.1652 - val_accuracy: 0.9506\n","adv train loss: 0.19340279205640157 train acc: 0.9437333345413208\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.3094 - accuracy: 0.9073 - val_loss: 0.1629 - val_accuracy: 0.9524\n","adv train loss: 0.18611354259053867 train acc: 0.9448666572570801\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 34us/sample - loss: 0.3096 - accuracy: 0.9042 - val_loss: 0.1522 - val_accuracy: 0.9547\n","adv train loss: 0.17658340806365014 train acc: 0.947700023651123\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2929 - accuracy: 0.9101 - val_loss: 0.1544 - val_accuracy: 0.9556\n","adv train loss: 0.16760945475498834 train acc: 0.9521333575248718\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2896 - accuracy: 0.9114 - val_loss: 0.1431 - val_accuracy: 0.9560\n","adv train loss: 0.1642782387495041 train acc: 0.9513999819755554\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.2746 - accuracy: 0.9161 - val_loss: 0.1449 - val_accuracy: 0.9558\n","adv train loss: 0.15851731547315914 train acc: 0.9540333151817322\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 33us/sample - loss: 0.2803 - accuracy: 0.9151 - val_loss: 0.1339 - val_accuracy: 0.9595\n","adv train loss: 0.15522445464034876 train acc: 0.9536666870117188\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.2730 - accuracy: 0.9158 - val_loss: 0.1412 - val_accuracy: 0.9580\n","adv train loss: 0.14933452184001605 train acc: 0.9560666680335999\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.2620 - accuracy: 0.9214 - val_loss: 0.1314 - val_accuracy: 0.9612\n","adv train loss: 0.1490524532566468 train acc: 0.956333339214325\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 37us/sample - loss: 0.2573 - accuracy: 0.9227 - val_loss: 0.1395 - val_accuracy: 0.9567\n","adv train loss: 0.14563745474318662 train acc: 0.9580000042915344\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 42us/sample - loss: 0.2639 - accuracy: 0.9206 - val_loss: 0.1324 - val_accuracy: 0.9588\n","adv train loss: 0.14193869857589403 train acc: 0.9578333497047424\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.2535 - accuracy: 0.9230 - val_loss: 0.1403 - val_accuracy: 0.9561\n","adv train loss: 0.1488127279818058 train acc: 0.9555666446685791\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.2640 - accuracy: 0.9189 - val_loss: 0.1358 - val_accuracy: 0.9570\n","adv train loss: 0.1459665158390999 train acc: 0.9581999778747559\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689898314935,"user_tz":420,"elapsed":6546,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"boN7aeGwbphD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f2e778b2-0803-4796-a22e-7f21bb9282c8"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.1402775631153956, 0.9617]\n","Adv model:\n","[0.1358160742379725, 0.957]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[30.704048516845702, 0.0203]\n","Adv model:\n","[3.211679522705078, 0.2333]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[9.01954021911621, 0.1164]\n","Adv model:\n","[15.926033908081054, 0.0269]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689898318225,"user_tz":420,"elapsed":3294,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"PCJO-dfxbphD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b662ba1-19c5-407f-83b1-7a66ab597660"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.1402775631153956\n","Test accuracy: 0.9617\n","Model: \"mnist-simple-cnn-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_10 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv_1 (Conv2D)             (None, 26, 26, 4)         40        \n","                                                                 \n"," conv_2 (Conv2D)             (None, 13, 13, 4)         68        \n","                                                                 \n"," flatten_9 (Flatten)         (None, 676)               0         \n","                                                                 \n"," dense (Dense)               (None, 20)                13540     \n","                                                                 \n"," logit (Dense)               (None, 10)                210       \n","                                                                 \n","=================================================================\n","Total params: 13,858\n","Trainable params: 13,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.1358160742379725\n","Test accuracy: 0.957\n","Model: \"mnist-simple-cnn-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_11 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv_1 (Conv2D)             (None, 26, 26, 4)         40        \n","                                                                 \n"," conv_2 (Conv2D)             (None, 13, 13, 4)         68        \n","                                                                 \n"," flatten_10 (Flatten)        (None, 676)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 20)                13540     \n","                                                                 \n"," logit (Dense)               (None, 10)                210       \n","                                                                 \n","=================================================================\n","Total params: 13,858\n","Trainable params: 13,858\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["cnn-sota"],"metadata":{"id":"ey2hTv36haIN"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"id":"O96HoAYihaIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normally trained model for comparision\n","\n","inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-sota-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689543960289,"user_tz":420,"elapsed":83035,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaafa732-2aed-4a05-9135-d45162aec5d8","id":"6m7iQVXzhaIW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9254"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 12s 192us/sample - loss: 0.2401 - accuracy: 0.9254 - val_loss: 0.0422 - val_accuracy: 0.9859\n","Epoch 2/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.0367 - val_accuracy: 0.9889\n","Epoch 3/20\n","60000/60000 [==============================] - 4s 60us/sample - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 4/20\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.0236 - val_accuracy: 0.9932\n","Epoch 5/20\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0257 - val_accuracy: 0.9925\n","Epoch 6/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0272 - val_accuracy: 0.9931\n","Epoch 7/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0266 - val_accuracy: 0.9927\n","Epoch 8/20\n","60000/60000 [==============================] - 4s 70us/sample - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0202 - val_accuracy: 0.9932\n","Epoch 9/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0208 - val_accuracy: 0.9941\n","Epoch 10/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0213 - val_accuracy: 0.9938\n","Epoch 11/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0213 - val_accuracy: 0.9943\n","Epoch 12/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9925\n","Epoch 13/20\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9954\n","Epoch 14/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0231 - val_accuracy: 0.9937\n","Epoch 15/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0239 - val_accuracy: 0.9940\n","Epoch 16/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0238 - val_accuracy: 0.9944\n","Epoch 17/20\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0248 - val_accuracy: 0.9940\n","Epoch 18/20\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0260 - val_accuracy: 0.9939\n","Epoch 19/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0249 - val_accuracy: 0.9948\n","Epoch 20/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0251 - val_accuracy: 0.9947\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7f89a01390>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-sota-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"HG6_QcwRhaIW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gldh00dJq9jC","executionInfo":{"status":"ok","timestamp":1689544974813,"user_tz":420,"elapsed":932281,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"9a4dce03-3be3-4d7c-866d-4c4b4408dee8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","59904/60000 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9265"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 4s 72us/sample - loss: 0.2336 - accuracy: 0.9266 - val_loss: 0.0420 - val_accuracy: 0.9869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.0300 - val_accuracy: 0.9901\n","adv train loss: 0.030231569734541698 train acc: 0.9902999997138977\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 68us/sample - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.0230 - val_accuracy: 0.9928\n","adv train loss: 0.02148217306341588 train acc: 0.9935666918754578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0208 - val_accuracy: 0.9931\n","adv train loss: 0.016763980462714486 train acc: 0.9946666955947876\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 5s 75us/sample - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.0238 - val_accuracy: 0.9920\n","adv train loss: 0.01356623228554769 train acc: 0.9959666728973389\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0219 - val_accuracy: 0.9935\n","adv train loss: 0.010391815545233355 train acc: 0.9966999888420105\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.0174 - val_accuracy: 0.9945\n","adv train loss: 0.008811341035453613 train acc: 0.9973333477973938\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0173 - val_accuracy: 0.9948\n","adv train loss: 0.007857911233859583 train acc: 0.9976000189781189\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.0207 - val_accuracy: 0.9939\n","adv train loss: 0.008768473670242626 train acc: 0.9978333115577698\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 64us/sample - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.0208 - val_accuracy: 0.9940\n","adv train loss: 0.010103383167441159 train acc: 0.9968666434288025\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9929\n","adv train loss: 0.006660927428381789 train acc: 0.9977666735649109\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0194 - val_accuracy: 0.9935\n","adv train loss: 0.005941494244543234 train acc: 0.9983333349227905\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9932\n","adv train loss: 0.004772425332066632 train acc: 0.9988999962806702\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0189 - val_accuracy: 0.9950\n","adv train loss: 0.005282013006851533 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0239 - val_accuracy: 0.9936\n","adv train loss: 0.005373753127626939 train acc: 0.9983999729156494\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0217 - val_accuracy: 0.9943\n","adv train loss: 0.004660386360459112 train acc: 0.9986333250999451\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0260 - val_accuracy: 0.9936\n","adv train loss: 0.004079835508772582 train acc: 0.9987333416938782\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0197 - val_accuracy: 0.9950\n","adv train loss: 0.004502995672669325 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9942\n","adv train loss: 0.0027133517270314616 train acc: 0.9993000030517578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9944\n","adv train loss: 0.005036794815134393 train acc: 0.9984999895095825\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nL56w7ZkrFAX","executionInfo":{"status":"ok","timestamp":1689544985681,"user_tz":420,"elapsed":9236,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"fa4178ab-66c9-4866-a349-44cb1c4bd6c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.025107924216459982, 0.9947]\n","Adv model:\n","[0.02079905009451977, 0.9944]\n","\n","Test loss and accuracy on adv samples from regular model:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Regular model:\n","[2.2156280811309816, 0.5203]\n","Adv model:\n","[0.6746757946014404, 0.7902]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[0.32085431804656983, 0.902]\n","Adv model:\n","[1.0280582367897033, 0.7158]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5GrvQB3q_Zx","executionInfo":{"status":"ok","timestamp":1689544987128,"user_tz":420,"elapsed":1458,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"3861166d-fe76-4394-f1e8-9cdc827fd8d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.025107924216459982\n","Test accuracy: 0.9947\n","Model: \"mnist-sota-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 200)               205000    \n","                                                                 \n"," dropout (Dropout)           (None, 200)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.02079905009451977\n","Test accuracy: 0.9944\n","Model: \"mnist-sota-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               205000    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 200)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"r6KaVFwUrL_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"448L8e9drMCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = Input(shape=(28, 28, 1))\n","x = Flatten()(inp)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","\n","model_test = tf.keras.Model(inputs=inp, outputs=x)\n","model_test.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),\n","              metrics=['accuracy'])\n","\n","art_model_test = KerasClassifier(model=model, clip_values=(0, 1))\n","mini_batch_size = 50\n","pgd_attack = ProjectedGradientDescent(art_model_test,\n","                                      eps=0.1,\n","                                      eps_step=0.005,\n","                                      max_iter=40,\n","                                      batch_size=mini_batch_size)\n"],"metadata":{"id":"_VAqMDiEtE_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adv = pgd_attack.generate(x_train[:10], batch_size=32)\n","plot_figure(adv[0], cmap='gray')\n","plot_figure(x_train[0], cmap='gray')\n","print(sum(sum(x_train[0] - adv[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["94df444328054527a1b644d07d53e2b9","748e7f3e4a964cacb6596c3e5f9aeb00","cd031a2ed3e045caa122c75e990b9c76","b4db8c95cec94184bb6c418a36b1bb88","b50ceef5084f4e8fbd7ef1236c20aff2","3ac20f8de3d0454c90e8a3051239e025","b8554873bf6b47399285c6c388c32d34","a48c8d11979a42eebe6d1fdc8445d5b1","1a8c451d35d243f1be2316ca44e2d9e4","6deb89426dcc4376adfd194ca4cccf67","a5a03885f12c4442a4787aadf7babebf","e1dc7d9add2e49b29674756df3526495","0dd7c1300aed4ceeb1682b2915aa554d","388c902bfdeb4e379eebcca096d724b1","eddc106ce49c42419455860a20f5e7f1","875c90c6c7934f9b80871cf69832ba1d","b1e20d8339bf4197b6948840c3925646","23524757da7c4966b950065e3f4551d0","a0ab84cd7cbd4ec88ccf1a8a89f912de","f94fd5ed117f477eac807cd9bce9e768","6fd5433880cf41e48777cc9d3a870ba5","9567c77d47a24d44bde26cbba54b4b64"]},"id":"RdaXwIl0q9Mo","executionInfo":{"status":"ok","timestamp":1689281556463,"user_tz":420,"elapsed":1067,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"d377b918-1d15-4d90-ad49-dc77210e6f76"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94df444328054527a1b644d07d53e2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["PGD - Iterations:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1dc7d9add2e49b29674756df3526495"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[-24.668528]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}