{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1loa5QTUmtNnWeL2ELnN-geJS5a2iGiW3","authorship_tag":"ABX9TyMGNSqfI78NC1xDUjDLWREH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"94df444328054527a1b644d07d53e2b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_748e7f3e4a964cacb6596c3e5f9aeb00","IPY_MODEL_cd031a2ed3e045caa122c75e990b9c76","IPY_MODEL_b4db8c95cec94184bb6c418a36b1bb88"],"layout":"IPY_MODEL_b50ceef5084f4e8fbd7ef1236c20aff2"}},"748e7f3e4a964cacb6596c3e5f9aeb00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ac20f8de3d0454c90e8a3051239e025","placeholder":"​","style":"IPY_MODEL_b8554873bf6b47399285c6c388c32d34","value":"PGD - Random Initializations: 100%"}},"cd031a2ed3e045caa122c75e990b9c76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a48c8d11979a42eebe6d1fdc8445d5b1","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1a8c451d35d243f1be2316ca44e2d9e4","value":1}},"b4db8c95cec94184bb6c418a36b1bb88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6deb89426dcc4376adfd194ca4cccf67","placeholder":"​","style":"IPY_MODEL_a5a03885f12c4442a4787aadf7babebf","value":" 1/1 [00:00&lt;00:00,  2.68it/s]"}},"b50ceef5084f4e8fbd7ef1236c20aff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ac20f8de3d0454c90e8a3051239e025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8554873bf6b47399285c6c388c32d34":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a48c8d11979a42eebe6d1fdc8445d5b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a8c451d35d243f1be2316ca44e2d9e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6deb89426dcc4376adfd194ca4cccf67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5a03885f12c4442a4787aadf7babebf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e1dc7d9add2e49b29674756df3526495":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dd7c1300aed4ceeb1682b2915aa554d","IPY_MODEL_388c902bfdeb4e379eebcca096d724b1","IPY_MODEL_eddc106ce49c42419455860a20f5e7f1"],"layout":"IPY_MODEL_875c90c6c7934f9b80871cf69832ba1d"}},"0dd7c1300aed4ceeb1682b2915aa554d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1e20d8339bf4197b6948840c3925646","placeholder":"​","style":"IPY_MODEL_23524757da7c4966b950065e3f4551d0","value":"PGD - Iterations:  52%"}},"388c902bfdeb4e379eebcca096d724b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0ab84cd7cbd4ec88ccf1a8a89f912de","max":40,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f94fd5ed117f477eac807cd9bce9e768","value":40}},"eddc106ce49c42419455860a20f5e7f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fd5433880cf41e48777cc9d3a870ba5","placeholder":"​","style":"IPY_MODEL_9567c77d47a24d44bde26cbba54b4b64","value":" 21/40 [00:00&lt;00:00, 97.01it/s]"}},"875c90c6c7934f9b80871cf69832ba1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"b1e20d8339bf4197b6948840c3925646":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23524757da7c4966b950065e3f4551d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0ab84cd7cbd4ec88ccf1a8a89f912de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f94fd5ed117f477eac807cd9bce9e768":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6fd5433880cf41e48777cc9d3a870ba5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9567c77d47a24d44bde26cbba54b4b64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install tensorflow_ranking\n","!pip install tf2onnx\n","!pip install adversarial-robustness-toolbox\n","!pip uninstall numpy\n","!pip install numpy==1.23.5"],"metadata":{"id":"N1rr9uiletu0"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5H9Rz649er0f","executionInfo":{"status":"ok","timestamp":1689713038018,"user_tz":420,"elapsed":12041,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"outputs":[],"source":["from tensorflow import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Input, Dense, Reshape, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n","from keras.initializers import GlorotUniform\n","import tensorflow as tf\n","import tensorflow_ranking as tfr\n","import tf2onnx\n","import numpy as np\n","from art.estimators.classification import KerasClassifier\n","from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent"]},{"cell_type":"code","source":["import sys\n","sys.path.append(sys.path.append('/content/drive/My Drive/CURIS/VeriX/train_networks'))"],"metadata":{"id":"DLBIohSmB0q_","executionInfo":{"status":"ok","timestamp":1689713038019,"user_tz":420,"elapsed":20,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NV-yxKvdgV07","executionInfo":{"status":"ok","timestamp":1689713046181,"user_tz":420,"elapsed":8180,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"337b3c4e-d0b9-40a5-e278-ea8b7280a2f3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"7vdrHaqPmF3d","executionInfo":{"status":"ok","timestamp":1689713049003,"user_tz":420,"elapsed":308,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["SEED = 137\n","output_path = 'drive/MyDrive/CURIS/VeriX/networks/'"],"metadata":{"id":"SBuoH7amV0RX","executionInfo":{"status":"ok","timestamp":1689713050341,"user_tz":420,"elapsed":2,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","x_train = x_train.astype('float32') / 255\n","x_test = x_test.astype('float32') / 255"],"metadata":{"id":"X1ZbugoifOQL","executionInfo":{"status":"ok","timestamp":1689713054631,"user_tz":420,"elapsed":3030,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9646e1e9-455b-4b16-8f25-d44c39870173"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","def plot_figure(image, path=None, cmap=None):\n","    fig = plt.figure()\n","    ax = plt.Axes(fig, [-0.5, -0.5, 1., 1.])\n","    ax.set_axis_off()\n","    fig.add_axes(ax)\n","    plt.imshow(image, cmap=cmap)\n","    if path is not None:\n","      plt.savefig(path, bbox_inches='tight')\n","    # plt.close(fig)"],"metadata":{"id":"TJij4mzOg34b","executionInfo":{"status":"ok","timestamp":1689545626061,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def eval_and_save(model):\n","  score = model.evaluate(x_test, y_test, verbose=0)\n","  print(\"Test loss:\", score[0])\n","  print(\"Test accuracy:\", score[1])\n","  model.summary()\n","  model.save(output_path + model.name + '.h5')\n","  # model_proto, _ = tf2onnx.convert.from_keras(model, output_path=output_path + model.name + '.onnx')"],"metadata":{"id":"1xIYjKSw4rC1","executionInfo":{"status":"ok","timestamp":1689713054631,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def print_weights(model):\n","  for layer in model.layers:\n","    print(layer.get_config())\n","    print(layer.get_weights())"],"metadata":{"id":"eDilkggLVqLk","executionInfo":{"status":"ok","timestamp":1689713054631,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train_pgd(model_pgd, num_epochs, alpha):\n","  art_model_pgd = KerasClassifier(model_pgd, clip_values=(0, 1))\n","  art_model_pgd.fit(x_train, y_train,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","  pgd_attack = ProjectedGradientDescent(art_model_pgd, eps=0.1, eps_step=0.01, max_iter=10, verbose=False)\n","\n","  num_samples = len(x_train)\n","  num_adv = int(num_samples * alpha)\n","  num_real = num_samples - num_adv\n","\n","  for i in range(num_epochs - 1):\n","    adv_indices = np.random.choice(x_train.shape[0], size=num_adv, replace=False)\n","    real_indices = np.random.choice(x_train.shape[0], size=num_real, replace=False)\n","    adv_samples = pgd_attack.generate(\n","        x_train[adv_indices],\n","        batch_size=128)\n","    x_real = x_train[real_indices]\n","    y_real = y_train[real_indices]\n","    x_adv = np.concatenate((adv_samples, x_real))\n","    y_adv = np.concatenate((y_train[adv_indices], y_real))\n","    permutation = np.random.permutation(num_samples)\n","    x_adv = x_adv[permutation]\n","    y_adv = y_adv[permutation]\n","    art_model_pgd.fit(x_adv, y_adv,\n","              batch_size=128,\n","              nb_epochs=1,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","    score = model_pgd.evaluate(adv_samples, y_train[adv_indices])\n","    print(f'adv train loss: {score[0]} train acc: {score[1]}')"],"metadata":{"id":"KOOgHT0NXFkU","executionInfo":{"status":"ok","timestamp":1689713055981,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, model_adv):\n","  print('Test loss and accuracy on original test data:')\n","  print('Regular model:')\n","  print(model.evaluate(x_test, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(x_test, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from regular model:')\n","  art_model_regular_pgd = KerasClassifier(model, clip_values=(0, 1))\n","  # pgd_attack_regular = ProjectedGradientDescent(art_model_regular_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_regular.generate(x_test, batch_size=128)\n","  fgm_attack_regular = FastGradientMethod(art_model_regular_pgd)\n","  adv = fgm_attack_regular.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))\n","  print('')\n","\n","  print('Test loss and accuracy on adv samples from adv model:')\n","  art_model_adv_pgd = KerasClassifier(model_adv, clip_values=(0, 1))\n","  # pgd_attack_adv = ProjectedGradientDescent(art_model_adv_pgd, eps=0.1, eps_step=0.01, max_iter=50, verbose=False)\n","  # adv = pgd_attack_adv.generate(x_test, batch_size=128)\n","  fgm_attack_adv = FastGradientMethod(art_model_adv_pgd)\n","  adv = fgm_attack_adv.generate(x_test, batch_size=128)\n","  print('Regular model:')\n","  print(model.evaluate(adv, y_test))\n","  print('Adv model:')\n","  print(model_adv.evaluate(adv, y_test))"],"metadata":{"id":"1qWWSKdVxury","executionInfo":{"status":"ok","timestamp":1689713057494,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SVzgmf_VZ3a0","executionInfo":{"status":"ok","timestamp":1689540884920,"user_tz":420,"elapsed":2,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":["10x2 fully connected"],"metadata":{"id":"mNzV_fNFZ3zx"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689713482171,"user_tz":420,"elapsed":4,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"hpVnc6g7Z3zx"},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-10x2-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=0,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGV3hmlSZ3zy","executionInfo":{"status":"ok","timestamp":1689713526194,"user_tz":420,"elapsed":43032,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"ac54b599-5b86-41c0-b9d3-f87ccfda608b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7d82da843820>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-10x2-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689540910518,"user_tz":420,"elapsed":18,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"pn3jCiT4Z3zy"},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"75b528b5-89f2-4db8-9a4d-f6cdf90fabc1","id":"RzoQm3LhZ3zy","executionInfo":{"status":"ok","timestamp":1689541432406,"user_tz":420,"elapsed":521905,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.8536 - accuracy: 0.7519 - val_loss: 0.4351 - val_accuracy: 0.8748\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.4941 - accuracy: 0.8552 - val_loss: 0.3617 - val_accuracy: 0.8967\n","adv train loss: 0.3693551545699437 train acc: 0.8914666771888733\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.5780 - accuracy: 0.8374 - val_loss: 0.3330 - val_accuracy: 0.9054\n","adv train loss: 0.36558063231309257 train acc: 0.8939666748046875\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.5044 - accuracy: 0.8515 - val_loss: 0.3116 - val_accuracy: 0.9088\n","adv train loss: 0.34451932666301727 train acc: 0.8981999754905701\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4876 - accuracy: 0.8574 - val_loss: 0.3040 - val_accuracy: 0.9118\n","adv train loss: 0.34177516326904295 train acc: 0.9014333486557007\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.4933 - accuracy: 0.8534 - val_loss: 0.2982 - val_accuracy: 0.9113\n","adv train loss: 0.3497435357014338 train acc: 0.9011333584785461\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4725 - accuracy: 0.8587 - val_loss: 0.2907 - val_accuracy: 0.9133\n","adv train loss: 0.3408006658275922 train acc: 0.9004666805267334\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4820 - accuracy: 0.8570 - val_loss: 0.2913 - val_accuracy: 0.9117\n","adv train loss: 0.34857543473243713 train acc: 0.8989333510398865\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.4729 - accuracy: 0.8587 - val_loss: 0.2857 - val_accuracy: 0.9154\n","adv train loss: 0.3408238809982936 train acc: 0.8999000191688538\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4645 - accuracy: 0.8594 - val_loss: 0.2854 - val_accuracy: 0.9164\n","adv train loss: 0.3388289579629898 train acc: 0.9006999731063843\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4687 - accuracy: 0.8600 - val_loss: 0.2813 - val_accuracy: 0.9170\n","adv train loss: 0.34059320375919344 train acc: 0.8992000222206116\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4660 - accuracy: 0.8601 - val_loss: 0.2845 - val_accuracy: 0.9133\n","adv train loss: 0.337933734635512 train acc: 0.9025999903678894\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.4598 - accuracy: 0.8620 - val_loss: 0.2723 - val_accuracy: 0.9201\n","adv train loss: 0.3358090846935908 train acc: 0.9028000235557556\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4648 - accuracy: 0.8597 - val_loss: 0.2811 - val_accuracy: 0.9157\n","adv train loss: 0.3381376169681549 train acc: 0.9021666646003723\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4629 - accuracy: 0.8613 - val_loss: 0.2715 - val_accuracy: 0.9219\n","adv train loss: 0.3325776980161667 train acc: 0.9049999713897705\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4746 - accuracy: 0.8573 - val_loss: 0.2774 - val_accuracy: 0.9169\n","adv train loss: 0.34183333323399223 train acc: 0.9023333191871643\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.4632 - accuracy: 0.8597 - val_loss: 0.2710 - val_accuracy: 0.9213\n","adv train loss: 0.343419833723704 train acc: 0.9034000039100647\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.4662 - accuracy: 0.8576 - val_loss: 0.2735 - val_accuracy: 0.9172\n","adv train loss: 0.34401528862317404 train acc: 0.9017999768257141\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.4584 - accuracy: 0.8600 - val_loss: 0.2660 - val_accuracy: 0.9235\n","adv train loss: 0.34177137869199115 train acc: 0.901366651058197\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.4595 - accuracy: 0.8612 - val_loss: 0.2729 - val_accuracy: 0.9176\n","adv train loss: 0.34434267234007515 train acc: 0.9014333486557007\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689541438712,"user_tz":420,"elapsed":6331,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"72758a29-8168-4ace-f8e8-4b92a7c7c211","id":"bLd8L1TFZ3zy"},"execution_count":61,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.20739639399051665, 0.9418]\n","Adv model:\n","[0.27289960238486527, 0.9176]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[36.185757897949216, 0.0212]\n","Adv model:\n","[3.1414361583709716, 0.1723]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[12.339515525817871, 0.0981]\n","Adv model:\n","[13.963685888671876, 0.041]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YZbUPNsaDfa","executionInfo":{"status":"ok","timestamp":1689541439070,"user_tz":420,"elapsed":372,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"5212be69-6065-49d7-de4a-0f1e8ce88f0e"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.20739639399051665\n","Test accuracy: 0.9418\n","Model: \"mnist-10x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_13 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_12 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                7850      \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                110       \n","                                                                 \n"," logit (Dense)               (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 8,070\n","Trainable params: 8,070\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.27289960238486527\n","Test accuracy: 0.9176\n","Model: \"mnist-10x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_14 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_13 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                7850      \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                110       \n","                                                                 \n"," logit (Dense)               (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 8,070\n","Trainable params: 8,070\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["30x2 fully connected"],"metadata":{"id":"naNeO7cyZ41Q"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689541439070,"user_tz":420,"elapsed":3,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"AuLtM1saZ41Q"},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-30x2-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P63H5JuUZ41Q","executionInfo":{"status":"ok","timestamp":1689541469024,"user_tz":420,"elapsed":29957,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"a68c77d6-79a0-42e6-b382-b70f2a3498a2"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 2s 25us/sample - loss: 0.5276 - accuracy: 0.8494 - val_loss: 0.2525 - val_accuracy: 0.9274\n","Epoch 2/20\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.2254 - accuracy: 0.9353 - val_loss: 0.1955 - val_accuracy: 0.9436\n","Epoch 3/20\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.1762 - accuracy: 0.9498 - val_loss: 0.1593 - val_accuracy: 0.9557\n","Epoch 4/20\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.1490 - accuracy: 0.9567 - val_loss: 0.1453 - val_accuracy: 0.9599\n","Epoch 5/20\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.1322 - accuracy: 0.9611 - val_loss: 0.1373 - val_accuracy: 0.9625\n","Epoch 6/20\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.1189 - accuracy: 0.9653 - val_loss: 0.1321 - val_accuracy: 0.9639\n","Epoch 7/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1082 - accuracy: 0.9682 - val_loss: 0.1265 - val_accuracy: 0.9651\n","Epoch 8/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0987 - accuracy: 0.9707 - val_loss: 0.1225 - val_accuracy: 0.9661\n","Epoch 9/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0915 - accuracy: 0.9729 - val_loss: 0.1196 - val_accuracy: 0.9664\n","Epoch 10/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0848 - accuracy: 0.9745 - val_loss: 0.1136 - val_accuracy: 0.9690\n","Epoch 11/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0779 - accuracy: 0.9768 - val_loss: 0.1135 - val_accuracy: 0.9702\n","Epoch 12/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0734 - accuracy: 0.9776 - val_loss: 0.1164 - val_accuracy: 0.9676\n","Epoch 13/20\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.0683 - accuracy: 0.9795 - val_loss: 0.1084 - val_accuracy: 0.9697\n","Epoch 14/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0644 - accuracy: 0.9807 - val_loss: 0.1169 - val_accuracy: 0.9676\n","Epoch 15/20\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.0611 - accuracy: 0.9816 - val_loss: 0.1143 - val_accuracy: 0.9683\n","Epoch 16/20\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.0569 - accuracy: 0.9826 - val_loss: 0.1151 - val_accuracy: 0.9696\n","Epoch 17/20\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.0538 - accuracy: 0.9836 - val_loss: 0.1094 - val_accuracy: 0.9719\n","Epoch 18/20\n","60000/60000 [==============================] - 2s 26us/sample - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.1116 - val_accuracy: 0.9716\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0475 - accuracy: 0.9853 - val_loss: 0.1203 - val_accuracy: 0.9703\n","Epoch 20/20\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.1213 - val_accuracy: 0.9695\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7d510e2b2590>"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(30, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(30, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-30x2-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689541469025,"user_tz":420,"elapsed":22,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"z4K-thMiZ41R"},"execution_count":65,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3bb53124-84f3-4da4-bd11-0016a437caf3","id":"R0E4X0oyZ41R","executionInfo":{"status":"ok","timestamp":1689541997539,"user_tz":420,"elapsed":528535,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 25us/sample - loss: 0.5278 - accuracy: 0.8476 - val_loss: 0.2398 - val_accuracy: 0.9315\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.3114 - accuracy: 0.9094 - val_loss: 0.1971 - val_accuracy: 0.9441\n","adv train loss: 0.2016845058778922 train acc: 0.9408666491508484\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.4002 - accuracy: 0.8864 - val_loss: 0.1787 - val_accuracy: 0.9475\n","adv train loss: 0.1965942677160104 train acc: 0.9426666498184204\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.3217 - accuracy: 0.9052 - val_loss: 0.1680 - val_accuracy: 0.9477\n","adv train loss: 0.18598947202761967 train acc: 0.9452333450317383\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2995 - accuracy: 0.9117 - val_loss: 0.1534 - val_accuracy: 0.9532\n","adv train loss: 0.1783645273307959 train acc: 0.9492999911308289\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 29us/sample - loss: 0.2781 - accuracy: 0.9178 - val_loss: 0.1400 - val_accuracy: 0.9560\n","adv train loss: 0.15582874858180681 train acc: 0.955133318901062\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.2637 - accuracy: 0.9211 - val_loss: 0.1425 - val_accuracy: 0.9559\n","adv train loss: 0.16349570033947627 train acc: 0.951366662979126\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2567 - accuracy: 0.9234 - val_loss: 0.1314 - val_accuracy: 0.9580\n","adv train loss: 0.1486477056701978 train acc: 0.955133318901062\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2434 - accuracy: 0.9278 - val_loss: 0.1232 - val_accuracy: 0.9623\n","adv train loss: 0.14286143117547034 train acc: 0.9593333601951599\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.2321 - accuracy: 0.9302 - val_loss: 0.1186 - val_accuracy: 0.9620\n","adv train loss: 0.14025040997217098 train acc: 0.9582333564758301\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2376 - accuracy: 0.9309 - val_loss: 0.1199 - val_accuracy: 0.9634\n","adv train loss: 0.13893063830435276 train acc: 0.9590333104133606\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2191 - accuracy: 0.9365 - val_loss: 0.1212 - val_accuracy: 0.9620\n","adv train loss: 0.13809793794651826 train acc: 0.9603666663169861\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2246 - accuracy: 0.9335 - val_loss: 0.1189 - val_accuracy: 0.9634\n","adv train loss: 0.14153029822309812 train acc: 0.9577000141143799\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.2161 - accuracy: 0.9367 - val_loss: 0.1156 - val_accuracy: 0.9629\n","adv train loss: 0.13253019862820706 train acc: 0.9609666466712952\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2152 - accuracy: 0.9356 - val_loss: 0.1175 - val_accuracy: 0.9643\n","adv train loss: 0.13339018096625804 train acc: 0.960099995136261\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2157 - accuracy: 0.9376 - val_loss: 0.1177 - val_accuracy: 0.9640\n","adv train loss: 0.1318137638072173 train acc: 0.9607666730880737\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2078 - accuracy: 0.9380 - val_loss: 0.1157 - val_accuracy: 0.9660\n","adv train loss: 0.12351177894572417 train acc: 0.9637333154678345\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 27us/sample - loss: 0.2009 - accuracy: 0.9400 - val_loss: 0.1109 - val_accuracy: 0.9668\n","adv train loss: 0.12073169180154801 train acc: 0.9644666910171509\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2139 - accuracy: 0.9363 - val_loss: 0.1172 - val_accuracy: 0.9649\n","adv train loss: 0.13349872500896454 train acc: 0.9607666730880737\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.2041 - accuracy: 0.9387 - val_loss: 0.1133 - val_accuracy: 0.9654\n","adv train loss: 0.12528678632924953 train acc: 0.9626666903495789\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689542003672,"user_tz":420,"elapsed":6143,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"198653fa-4b4a-4de9-9628-a0f786e393a3","id":"n6YOrGfFZ41R"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.1212972495779628, 0.9695]\n","Adv model:\n","[0.11326198044400662, 0.9654]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[36.56288490600586, 0.0192]\n","Adv model:\n","[2.4903115707397463, 0.331]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[11.530889402770995, 0.0937]\n","Adv model:\n","[15.03641513671875, 0.0174]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uj7eSMGRa-K9","executionInfo":{"status":"ok","timestamp":1689542006788,"user_tz":420,"elapsed":3119,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"07548b13-4aa2-4775-ecc2-a9f5e525b915"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.1212972495779628\n","Test accuracy: 0.9695\n","Model: \"mnist-30x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_15 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_14 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                23550     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 24,790\n","Trainable params: 24,790\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.11326198044400662\n","Test accuracy: 0.9654\n","Model: \"mnist-30x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_16 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_15 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 30)                23550     \n","                                                                 \n"," dense_2 (Dense)             (None, 30)                930       \n","                                                                 \n"," logit (Dense)               (None, 10)                310       \n","                                                                 \n","=================================================================\n","Total params: 24,790\n","Trainable params: 24,790\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["100x2 fully connected"],"metadata":{"id":"6VVT-pBU6xbD"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"id":"EX0g9sERb6uD","executionInfo":{"status":"ok","timestamp":1689542006789,"user_tz":420,"elapsed":23,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":69,"outputs":[]},{"cell_type":"code","source":["# normally trained model for compariaon\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-100x2-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"id":"oURqqMajArni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Flatten()(inputs)\n","x = Dense(100, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(100, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-100x2-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"CaPQ3vFIfSZQ","executionInfo":{"status":"ok","timestamp":1689542035931,"user_tz":420,"elapsed":1792,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":71,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTxLq2rZX086","executionInfo":{"status":"ok","timestamp":1689542570898,"user_tz":420,"elapsed":534971,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"3b7c8153-6f45-4e00-f0f4-42da46d4a286"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 38us/sample - loss: 0.3419 - accuracy: 0.9023 - val_loss: 0.1663 - val_accuracy: 0.9528\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2099 - accuracy: 0.9390 - val_loss: 0.1272 - val_accuracy: 0.9616\n","adv train loss: 0.11583543387254079 train acc: 0.9661999940872192\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.2420 - accuracy: 0.9310 - val_loss: 0.1089 - val_accuracy: 0.9670\n","adv train loss: 0.09941264968042572 train acc: 0.9711999893188477\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1742 - accuracy: 0.9507 - val_loss: 0.1028 - val_accuracy: 0.9663\n","adv train loss: 0.08998345837518573 train acc: 0.9737666845321655\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 30us/sample - loss: 0.1658 - accuracy: 0.9528 - val_loss: 0.0924 - val_accuracy: 0.9690\n","adv train loss: 0.0813308767721057 train acc: 0.9769333600997925\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 24us/sample - loss: 0.1518 - accuracy: 0.9562 - val_loss: 0.0856 - val_accuracy: 0.9733\n","adv train loss: 0.07186165034721295 train acc: 0.9795666933059692\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1418 - accuracy: 0.9595 - val_loss: 0.0818 - val_accuracy: 0.9745\n","adv train loss: 0.06817085386974116 train acc: 0.9803333282470703\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1378 - accuracy: 0.9615 - val_loss: 0.0882 - val_accuracy: 0.9716\n","adv train loss: 0.06530712641775609 train acc: 0.9812999963760376\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1359 - accuracy: 0.9616 - val_loss: 0.0725 - val_accuracy: 0.9765\n","adv train loss: 0.057318250879148644 train acc: 0.9826666712760925\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.1341 - accuracy: 0.9614 - val_loss: 0.0785 - val_accuracy: 0.9739\n","adv train loss: 0.05701386227483551 train acc: 0.9829333424568176\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1288 - accuracy: 0.9626 - val_loss: 0.0771 - val_accuracy: 0.9749\n","adv train loss: 0.055315910010163984 train acc: 0.9843000173568726\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1278 - accuracy: 0.9626 - val_loss: 0.0719 - val_accuracy: 0.9760\n","adv train loss: 0.05343928419624766 train acc: 0.9849666953086853\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.1253 - accuracy: 0.9657 - val_loss: 0.0746 - val_accuracy: 0.9764\n","adv train loss: 0.05038342680347462 train acc: 0.9854666590690613\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 31us/sample - loss: 0.1208 - accuracy: 0.9655 - val_loss: 0.0666 - val_accuracy: 0.9791\n","adv train loss: 0.046640743613988164 train acc: 0.986466646194458\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1240 - accuracy: 0.9655 - val_loss: 0.0662 - val_accuracy: 0.9782\n","adv train loss: 0.04686044779643416 train acc: 0.986133337020874\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 20us/sample - loss: 0.1139 - accuracy: 0.9671 - val_loss: 0.0657 - val_accuracy: 0.9807\n","adv train loss: 0.04560452558305114 train acc: 0.9872999787330627\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1158 - accuracy: 0.9675 - val_loss: 0.0675 - val_accuracy: 0.9790\n","adv train loss: 0.042968049903896945 train acc: 0.9881666898727417\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 28us/sample - loss: 0.1083 - accuracy: 0.9687 - val_loss: 0.0628 - val_accuracy: 0.9803\n","adv train loss: 0.04298357913546885 train acc: 0.9880333542823792\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.1088 - accuracy: 0.9691 - val_loss: 0.0672 - val_accuracy: 0.9787\n","adv train loss: 0.04094130084185551 train acc: 0.989133358001709\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 1s 21us/sample - loss: 0.1086 - accuracy: 0.9689 - val_loss: 0.0669 - val_accuracy: 0.9798\n","adv train loss: 0.04456338032695154 train acc: 0.9875666499137878\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4IpKJN3xrYJ2","executionInfo":{"status":"ok","timestamp":1689542578163,"user_tz":420,"elapsed":7286,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"81a93a07-7aa1-41b3-c4e6-1c7429664aaa"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.11203716154028807, 0.9759]\n","Adv model:\n","[0.06693782015112229, 0.9798]\n","\n","Test loss and accuracy on adv samples from regular model:\n","Regular model:\n","[38.370378717041014, 0.0239]\n","Adv model:\n","[1.632470408821106, 0.5301]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[10.202788330078125, 0.1479]\n","Adv model:\n","[17.258878359985353, 0.017]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"id":"qtJuakrFpRT-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689542580704,"user_tz":420,"elapsed":2544,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"72a1de68-269d-4f7c-fbc8-7451b8fada42"},"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.11203716154028807\n","Test accuracy: 0.9759\n","Model: \"mnist-100x2-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_17 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_16 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.06693782015112229\n","Test accuracy: 0.9798\n","Model: \"mnist-100x2-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_18 (InputLayer)       [(None, 28, 28, 1)]       0         \n","                                                                 \n"," flatten_17 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 100)               78500     \n","                                                                 \n"," dense_2 (Dense)             (None, 100)               10100     \n","                                                                 \n"," logit (Dense)               (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 89,610\n","Trainable params: 89,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"crnHiwZWri6s","executionInfo":{"status":"ok","timestamp":1689542580704,"user_tz":420,"elapsed":11,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":["cnn-simple"],"metadata":{"id":"K1HqrwdNbHAD"}},{"cell_type":"code","source":["model = Sequential(name='mnist-simple-cnn')\n","model.add(Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Flatten())\n","model.add(Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED)))\n","\n","model.compile(loss=tfr.keras.losses.SoftmaxLoss(),\n","              #loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=2,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VoJNdFDOw7QX","executionInfo":{"status":"ok","timestamp":1689546355047,"user_tz":420,"elapsed":8259,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"f242c57f-8b76-4a53-e47b-bc2f0bddd5fa"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","469/469 [==============================] - 5s 6ms/step - loss: 0.5075 - accuracy: 0.8483 - val_loss: 0.2483 - val_accuracy: 0.9310\n","Epoch 2/2\n","469/469 [==============================] - 2s 4ms/step - loss: 0.2391 - accuracy: 0.9319 - val_loss: 0.2036 - val_accuracy: 0.9422\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7c304efe5c60>"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model = Sequential(name='mnist-simple-cnn')\n","model.add(Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Flatten())\n","model.add(Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED)))\n","model.add(Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED)))\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=20,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2JJ0suPvPyX","executionInfo":{"status":"ok","timestamp":1689545198293,"user_tz":420,"elapsed":35111,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"32818277-048f-4fc4-bc35-23ceb8b6e0a3"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - 3s 42us/sample - loss: 8.5097 - accuracy: 0.1432 - val_loss: 7.4022 - val_accuracy: 0.1112\n","Epoch 2/20\n","60000/60000 [==============================] - 2s 34us/sample - loss: 8.9047 - accuracy: 0.1082 - val_loss: 8.9711 - val_accuracy: 0.1047\n","Epoch 3/20\n","60000/60000 [==============================] - 2s 36us/sample - loss: 9.0251 - accuracy: 0.1240 - val_loss: 9.1333 - val_accuracy: 0.1487\n","Epoch 4/20\n","60000/60000 [==============================] - 2s 28us/sample - loss: 8.5461 - accuracy: 0.1244 - val_loss: 7.8310 - val_accuracy: 0.0980\n","Epoch 5/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 7.8928 - accuracy: 0.1392 - val_loss: 7.8336 - val_accuracy: 0.1366\n","Epoch 6/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 8.2643 - accuracy: 0.1425 - val_loss: 8.5334 - val_accuracy: 0.1365\n","Epoch 7/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 8.5942 - accuracy: 0.1426 - val_loss: 8.5400 - val_accuracy: 0.1366\n","Epoch 8/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 8.4942 - accuracy: 0.1426 - val_loss: 7.1558 - val_accuracy: 0.1361\n","Epoch 9/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 8.8409 - accuracy: 0.1207 - val_loss: 9.5081 - val_accuracy: 0.1003\n","Epoch 10/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 9.1530 - accuracy: 0.0996 - val_loss: 8.7489 - val_accuracy: 0.0981\n","Epoch 11/20\n","60000/60000 [==============================] - 2s 29us/sample - loss: 8.5141 - accuracy: 0.0991 - val_loss: 8.1912 - val_accuracy: 0.0967\n","Epoch 12/20\n","60000/60000 [==============================] - 3s 48us/sample - loss: 7.9948 - accuracy: 0.0977 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 13/20\n","60000/60000 [==============================] - 3s 52us/sample - loss: 7.6134 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 14/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 15/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 16/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 17/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 18/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 19/20\n","60000/60000 [==============================] - 1s 24us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n","Epoch 20/20\n","60000/60000 [==============================] - 1s 23us/sample - loss: 7.6131 - accuracy: 0.0971 - val_loss: 7.6110 - val_accuracy: 0.0948\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7f06d18400>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=x, name='mnist-simple-cnn-normal')\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=5,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lUa502OLbIfq","executionInfo":{"status":"ok","timestamp":1689545121889,"user_tz":420,"elapsed":10738,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"b2a9c49f-6cf0-4129-9970-c6e622b38494"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/5\n","60000/60000 [==============================] - 3s 55us/sample - loss: 7.2515 - accuracy: 0.1271 - val_loss: 7.2376 - val_accuracy: 0.1135\n","Epoch 2/5\n","60000/60000 [==============================] - 1s 24us/sample - loss: 7.9399 - accuracy: 0.1136 - val_loss: 6.4893 - val_accuracy: 0.1135\n","Epoch 3/5\n","60000/60000 [==============================] - 1s 25us/sample - loss: 6.8265 - accuracy: 0.1124 - val_loss: 6.8815 - val_accuracy: 0.1135\n","Epoch 4/5\n","60000/60000 [==============================] - 1s 24us/sample - loss: 6.7748 - accuracy: 0.1124 - val_loss: 6.8519 - val_accuracy: 0.1135\n","Epoch 5/5\n","60000/60000 [==============================] - 1s 24us/sample - loss: 6.9544 - accuracy: 0.1124 - val_loss: 6.8680 - val_accuracy: 0.1135\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7f06de9420>"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(4, (3, 3), name='conv_1', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(4, (2, 2), strides=(2, 2), name='conv_2', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Flatten()(x)\n","x = Dense(20, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=x, name='mnist-simple-cnn-pgd')\n","\n","model_pgd.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"Q0zV5Q4cbItp","executionInfo":{"status":"ok","timestamp":1689545089493,"user_tz":420,"elapsed":984,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["art_model_pgd = KerasClassifier(model_pgd, clip_values=(0, 1))\n","art_model_pgd.fit(x_train, y_train,\n","            batch_size=128,\n","            nb_epochs=1,\n","            verbose=1,\n","            validation_data=(x_test, y_test))\n","pgd_attack = ProjectedGradientDescent(art_model_pgd, eps=0.1, eps_step=0.01, max_iter=10, verbose=False)\n","\n","num_samples = len(x_train)\n","num_adv = int(num_samples * alpha)\n","num_real = num_samples - num_adv\n","\n","for i in range(5):\n","  adv_indices = np.random.choice(x_train.shape[0], size=num_adv, replace=False)\n","  real_indices = np.random.choice(x_train.shape[0], size=num_real, replace=False)\n","  adv_samples = pgd_attack.generate(\n","      x_train[adv_indices],\n","      batch_size=128)\n","  x_real = x_train[real_indices]\n","  y_real = y_train[real_indices]\n","  x_adv = np.concatenate((adv_samples, x_real))\n","  y_adv = np.concatenate((y_train[adv_indices], y_real))\n","  permutation = np.random.permutation(num_samples)\n","  x_adv = x_adv[permutation]\n","  y_adv = y_adv[permutation]\n","  art_model_pgd.fit(x_adv, y_adv,\n","            batch_size=128,\n","            nb_epochs=1,\n","            verbose=1,\n","            validation_data=(x_test, y_test))\n","  score = model_pgd.evaluate(adv_samples, y_train[adv_indices])\n","  print(f'adv train loss: {score[0]} train acc: {score[1]}')\n","  print_weights(model_pgd)\n","  print('=============')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"CWu1iOUxsOTc","executionInfo":{"status":"error","timestamp":1689545102504,"user_tz":420,"elapsed":10489,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"578139b0-1353-48db-b818-b57e6e6b2560"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 2s 40us/sample - loss: 8.0123 - accuracy: 0.1150 - val_loss: 8.4999 - val_accuracy: 0.1487\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-8f2aa082589a>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0madv_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_adv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mreal_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   adv_samples = pgd_attack.generate(\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madv_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       batch_size=128)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[1;32m    199\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating adversarial samples.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/art/attacks/evasion/projected_gradient_descent/projected_gradient_descent_numpy.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_max_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi_max_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                         batch = self._compute(\n\u001b[0m\u001b[1;32m    363\u001b[0m                             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_index_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, x, x_init, y, mask, eps, eps_step, project, random_init, batch_id_ext, decay, momentum)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;31m# Get perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;31m# Compute batch_eps and batch_eps_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36m_compute_perturbation\u001b[0;34m(self, x, y, mask, decay, momentum)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;31m# Get gradient wrt loss; invert it if attack is targeted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Write summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/art/estimators/classification/keras.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, x, y, training_mode, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_preprocessing_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4606\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4608\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4609\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4610\u001b[0m         output_structure = tf.nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1482\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m                                                run_metadata_ptr)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"id":"bWpstsChbnGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1689543792815,"user_tz":420,"elapsed":337304,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"boN7aeGwbphD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"executionInfo":{"status":"aborted","timestamp":1689543792816,"user_tz":420,"elapsed":336584,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"id":"PCJO-dfxbphD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["cnn-sota"],"metadata":{"id":"ey2hTv36haIN"}},{"cell_type":"code","source":["num_epochs = 20\n","alpha = 0.5 # proportion of adv samples"],"metadata":{"id":"O96HoAYihaIW","executionInfo":{"status":"ok","timestamp":1689543850300,"user_tz":420,"elapsed":1,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# normally trained model for comparision\n","\n","inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-sota-normal')\n","model.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])\n","model.fit(x_train, y_train,\n","          batch_size=128,\n","          epochs=num_epochs,\n","          verbose=1,\n","          validation_data=(x_test, y_test))"],"metadata":{"executionInfo":{"status":"ok","timestamp":1689543960289,"user_tz":420,"elapsed":83035,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaafa732-2aed-4a05-9135-d45162aec5d8","id":"6m7iQVXzhaIW"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/20\n","60000/60000 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9254"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 12s 192us/sample - loss: 0.2401 - accuracy: 0.9254 - val_loss: 0.0422 - val_accuracy: 0.9859\n","Epoch 2/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0690 - accuracy: 0.9798 - val_loss: 0.0367 - val_accuracy: 0.9889\n","Epoch 3/20\n","60000/60000 [==============================] - 4s 60us/sample - loss: 0.0482 - accuracy: 0.9862 - val_loss: 0.0205 - val_accuracy: 0.9932\n","Epoch 4/20\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0379 - accuracy: 0.9886 - val_loss: 0.0236 - val_accuracy: 0.9932\n","Epoch 5/20\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0257 - val_accuracy: 0.9925\n","Epoch 6/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0272 - accuracy: 0.9914 - val_loss: 0.0272 - val_accuracy: 0.9931\n","Epoch 7/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0238 - accuracy: 0.9926 - val_loss: 0.0266 - val_accuracy: 0.9927\n","Epoch 8/20\n","60000/60000 [==============================] - 4s 70us/sample - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.0202 - val_accuracy: 0.9932\n","Epoch 9/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0189 - accuracy: 0.9945 - val_loss: 0.0208 - val_accuracy: 0.9941\n","Epoch 10/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0213 - val_accuracy: 0.9938\n","Epoch 11/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0213 - val_accuracy: 0.9943\n","Epoch 12/20\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0332 - val_accuracy: 0.9925\n","Epoch 13/20\n","60000/60000 [==============================] - 4s 71us/sample - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0194 - val_accuracy: 0.9954\n","Epoch 14/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0231 - val_accuracy: 0.9937\n","Epoch 15/20\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.0239 - val_accuracy: 0.9940\n","Epoch 16/20\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0109 - accuracy: 0.9968 - val_loss: 0.0238 - val_accuracy: 0.9944\n","Epoch 17/20\n","60000/60000 [==============================] - 4s 74us/sample - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0248 - val_accuracy: 0.9940\n","Epoch 18/20\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0260 - val_accuracy: 0.9939\n","Epoch 19/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0249 - val_accuracy: 0.9948\n","Epoch 20/20\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0251 - val_accuracy: 0.9947\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7f89a01390>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# model for adversarial training with pgd\n","inputs = Input(shape=(28, 28, 1))\n","x = Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_initializer=GlorotUniform(seed=SEED))(inputs)\n","x = Conv2D(32, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Conv2D(64, (3, 3), activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = MaxPooling2D(pool_size=(2, 2))(x)\n","x = Flatten()(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dropout(0.5, seed=SEED)(x)\n","x = Dense(200, activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","outputs = Dense(10, name='logit', activation='softmax', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","model_pgd = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist-sota-pgd')\n","model_pgd.compile(loss='categorical_crossentropy',\n","              # loss=tf.keras.losses.CategoricalCrossentropy(),\n","              # loss=tfr.keras.losses.SoftmaxLoss(),\n","              optimizer=keras.optimizers.legacy.Adam(),\n","              metrics=['accuracy'])"],"metadata":{"id":"HG6_QcwRhaIW","executionInfo":{"status":"ok","timestamp":1689544016030,"user_tz":420,"elapsed":843,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train_pgd(model_pgd, num_epochs, alpha)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gldh00dJq9jC","executionInfo":{"status":"ok","timestamp":1689544974813,"user_tz":420,"elapsed":932281,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"9a4dce03-3be3-4d7c-866d-4c4b4408dee8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","59904/60000 [============================>.] - ETA: 0s - loss: 0.2339 - accuracy: 0.9265"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates = self.state_updates\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r60000/60000 [==============================] - 4s 72us/sample - loss: 0.2336 - accuracy: 0.9266 - val_loss: 0.0420 - val_accuracy: 0.9869\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0874 - accuracy: 0.9732 - val_loss: 0.0300 - val_accuracy: 0.9901\n","adv train loss: 0.030231569734541698 train acc: 0.9902999997138977\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 68us/sample - loss: 0.0540 - accuracy: 0.9844 - val_loss: 0.0230 - val_accuracy: 0.9928\n","adv train loss: 0.02148217306341588 train acc: 0.9935666918754578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 72us/sample - loss: 0.0529 - accuracy: 0.9845 - val_loss: 0.0208 - val_accuracy: 0.9931\n","adv train loss: 0.016763980462714486 train acc: 0.9946666955947876\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 5s 75us/sample - loss: 0.0427 - accuracy: 0.9875 - val_loss: 0.0238 - val_accuracy: 0.9920\n","adv train loss: 0.01356623228554769 train acc: 0.9959666728973389\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 73us/sample - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0219 - val_accuracy: 0.9935\n","adv train loss: 0.010391815545233355 train acc: 0.9966999888420105\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.0341 - accuracy: 0.9903 - val_loss: 0.0174 - val_accuracy: 0.9945\n","adv train loss: 0.008811341035453613 train acc: 0.9973333477973938\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0426 - accuracy: 0.9870 - val_loss: 0.0173 - val_accuracy: 0.9948\n","adv train loss: 0.007857911233859583 train acc: 0.9976000189781189\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0301 - accuracy: 0.9915 - val_loss: 0.0207 - val_accuracy: 0.9939\n","adv train loss: 0.008768473670242626 train acc: 0.9978333115577698\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 64us/sample - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.0208 - val_accuracy: 0.9940\n","adv train loss: 0.010103383167441159 train acc: 0.9968666434288025\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 4s 59us/sample - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.0228 - val_accuracy: 0.9929\n","adv train loss: 0.006660927428381789 train acc: 0.9977666735649109\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.0307 - accuracy: 0.9902 - val_loss: 0.0194 - val_accuracy: 0.9935\n","adv train loss: 0.005941494244543234 train acc: 0.9983333349227905\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0217 - val_accuracy: 0.9932\n","adv train loss: 0.004772425332066632 train acc: 0.9988999962806702\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0189 - val_accuracy: 0.9950\n","adv train loss: 0.005282013006851533 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0204 - accuracy: 0.9941 - val_loss: 0.0239 - val_accuracy: 0.9936\n","adv train loss: 0.005373753127626939 train acc: 0.9983999729156494\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0230 - accuracy: 0.9930 - val_loss: 0.0217 - val_accuracy: 0.9943\n","adv train loss: 0.004660386360459112 train acc: 0.9986333250999451\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0260 - val_accuracy: 0.9936\n","adv train loss: 0.004079835508772582 train acc: 0.9987333416938782\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0197 - val_accuracy: 0.9950\n","adv train loss: 0.004502995672669325 train acc: 0.998533308506012\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0172 - accuracy: 0.9950 - val_loss: 0.0242 - val_accuracy: 0.9942\n","adv train loss: 0.0027133517270314616 train acc: 0.9993000030517578\n","Train on 60000 samples, validate on 10000 samples\n","60000/60000 [==============================] - 3s 57us/sample - loss: 0.0185 - accuracy: 0.9944 - val_loss: 0.0208 - val_accuracy: 0.9944\n","adv train loss: 0.005036794815134393 train acc: 0.9984999895095825\n"]}]},{"cell_type":"code","source":["evaluate(model, model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nL56w7ZkrFAX","executionInfo":{"status":"ok","timestamp":1689544985681,"user_tz":420,"elapsed":9236,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"fa4178ab-66c9-4866-a349-44cb1c4bd6c4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss and accuracy on original test data:\n","Regular model:\n","[0.025107924216459982, 0.9947]\n","Adv model:\n","[0.02079905009451977, 0.9944]\n","\n","Test loss and accuracy on adv samples from regular model:\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n","  updates=self.state_updates,\n"]},{"output_type":"stream","name":"stdout","text":["Regular model:\n","[2.2156280811309816, 0.5203]\n","Adv model:\n","[0.6746757946014404, 0.7902]\n","\n","Test loss and accuracy on adv samples from adv model:\n","Regular model:\n","[0.32085431804656983, 0.902]\n","Adv model:\n","[1.0280582367897033, 0.7158]\n"]}]},{"cell_type":"code","source":["eval_and_save(model)\n","eval_and_save(model_pgd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5GrvQB3q_Zx","executionInfo":{"status":"ok","timestamp":1689544987128,"user_tz":420,"elapsed":1458,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"3861166d-fe76-4394-f1e8-9cdc827fd8d5"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Test loss: 0.025107924216459982\n","Test accuracy: 0.9947\n","Model: \"mnist-sota-normal\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 1024)              0         \n","                                                                 \n"," dense (Dense)               (None, 200)               205000    \n","                                                                 \n"," dropout (Dropout)           (None, 200)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n","Test loss: 0.02079905009451977\n","Test accuracy: 0.9944\n","Model: \"mnist-sota-pgd\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 10, 10, 64)        18496     \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 4, 4, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_1 (Flatten)         (None, 1024)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 200)               205000    \n","                                                                 \n"," dropout_1 (Dropout)         (None, 200)               0         \n","                                                                 \n"," dense_3 (Dense)             (None, 200)               40200     \n","                                                                 \n"," logit (Dense)               (None, 10)                2010      \n","                                                                 \n","=================================================================\n","Total params: 312,202\n","Trainable params: 312,202\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"r6KaVFwUrL_S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"448L8e9drMCm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = Input(shape=(28, 28, 1))\n","x = Flatten()(inp)\n","x = Dense(10, name='dense_1', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='dense_2', activation='relu', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","x = Dense(10, name='logit', kernel_initializer=GlorotUniform(seed=SEED))(x)\n","\n","model_test = tf.keras.Model(inputs=inp, outputs=x)\n","model_test.compile(loss='categorical_crossentropy',\n","              optimizer=keras.optimizers.legacy.Adam(learning_rate=0.001),\n","              metrics=['accuracy'])\n","\n","art_model_test = KerasClassifier(model=model, clip_values=(0, 1))\n","mini_batch_size = 50\n","pgd_attack = ProjectedGradientDescent(art_model_test,\n","                                      eps=0.1,\n","                                      eps_step=0.005,\n","                                      max_iter=40,\n","                                      batch_size=mini_batch_size)\n"],"metadata":{"id":"_VAqMDiEtE_S","executionInfo":{"status":"ok","timestamp":1689281554254,"user_tz":420,"elapsed":371,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["adv = pgd_attack.generate(x_train[:10], batch_size=32)\n","plot_figure(adv[0], cmap='gray')\n","plot_figure(x_train[0], cmap='gray')\n","print(sum(sum(x_train[0] - adv[0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["94df444328054527a1b644d07d53e2b9","748e7f3e4a964cacb6596c3e5f9aeb00","cd031a2ed3e045caa122c75e990b9c76","b4db8c95cec94184bb6c418a36b1bb88","b50ceef5084f4e8fbd7ef1236c20aff2","3ac20f8de3d0454c90e8a3051239e025","b8554873bf6b47399285c6c388c32d34","a48c8d11979a42eebe6d1fdc8445d5b1","1a8c451d35d243f1be2316ca44e2d9e4","6deb89426dcc4376adfd194ca4cccf67","a5a03885f12c4442a4787aadf7babebf","e1dc7d9add2e49b29674756df3526495","0dd7c1300aed4ceeb1682b2915aa554d","388c902bfdeb4e379eebcca096d724b1","eddc106ce49c42419455860a20f5e7f1","875c90c6c7934f9b80871cf69832ba1d","b1e20d8339bf4197b6948840c3925646","23524757da7c4966b950065e3f4551d0","a0ab84cd7cbd4ec88ccf1a8a89f912de","f94fd5ed117f477eac807cd9bce9e768","6fd5433880cf41e48777cc9d3a870ba5","9567c77d47a24d44bde26cbba54b4b64"]},"id":"RdaXwIl0q9Mo","executionInfo":{"status":"ok","timestamp":1689281556463,"user_tz":420,"elapsed":1067,"user":{"displayName":"Kaia Li","userId":"09671887922309786692"}},"outputId":"d377b918-1d15-4d90-ad49-dc77210e6f76"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["PGD - Random Initializations:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94df444328054527a1b644d07d53e2b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["PGD - Iterations:   0%|          | 0/40 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1dc7d9add2e49b29674756df3526495"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[-24.668528]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}